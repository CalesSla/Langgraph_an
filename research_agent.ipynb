{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Namespace for ArXiv's Atom-based XML format.\n",
    "ARXIV_NAMESPACE = '{http://www.w3.org/2005/Atom}'\n",
    "\n",
    "def extract_from_arxiv(search_query='cat:cs.AI', max_results=100, json_file_path='files/arxiv_dataset.json'):\n",
    "    \"\"\"\n",
    "    Fetches papers from the ArXiv API based on a search query, saves them as JSON, \n",
    "    and returns a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        search_query (str): The search query for ArXiv (default is 'cat:cs.AI').\n",
    "        max_results (int): The maximum number of results to retrieve (default is 100).\n",
    "        json_file_path (str): File path where JSON data will be saved.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the extracted paper information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct the URL for the API request.\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&max_results={max_results}'\n",
    "    \n",
    "    # Send a GET request to the ArXiv API.\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Parse the XML response.\n",
    "    root = ET.fromstring(response.content)\n",
    "    \n",
    "    papers = []\n",
    "    \n",
    "    # Loop through each \"entry\" in the XML, representing a single paper.\n",
    "    for entry in root.findall(f'{ARXIV_NAMESPACE}entry'):\n",
    "        title = entry.find(f'{ARXIV_NAMESPACE}title').text.strip()\n",
    "        summary = entry.find(f'{ARXIV_NAMESPACE}summary').text.strip()\n",
    "\n",
    "        # Get the authors of the paper.\n",
    "        author_elements = entry.findall(f'{ARXIV_NAMESPACE}author')\n",
    "        authors = [author.find(f'{ARXIV_NAMESPACE}name').text for author in author_elements]\n",
    "\n",
    "        # Get the paper's URL.\n",
    "        paper_url = entry.find(f'{ARXIV_NAMESPACE}id').text\n",
    "        arxiv_id = paper_url.split('/')[-1]\n",
    "\n",
    "        # Check for the PDF link.\n",
    "        pdf_link = next((link.attrib['href'] for link in entry.findall(f'{ARXIV_NAMESPACE}link') \n",
    "                         if link.attrib.get('title') == 'pdf'), None)\n",
    "\n",
    "        papers.append({\n",
    "            'title': title,\n",
    "            'summary': summary,\n",
    "            'authors': authors,\n",
    "            'arxiv_id': arxiv_id,\n",
    "            'url': paper_url,\n",
    "            'pdf_link': pdf_link\n",
    "        })\n",
    "    \n",
    "    # Convert list into a pandas DataFrame.\n",
    "    df = pd.DataFrame(papers)\n",
    "    \n",
    "    # Save the DataFrame to a JSON file.\n",
    "    with open(json_file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(papers, f, ensure_ascii=False, indent=4)\n",
    "        print(f'Data saved to {json_file_path} ...')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to files/arxiv_dataset.json ...\n"
     ]
    }
   ],
   "source": [
    "df = extract_from_arxiv(max_results=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Dynamic Backtracking', 'summary': 'Because of their occasional need to return to shallow points in a search\\ntree, existing backtracking methods can sometimes erase meaningful progress\\ntoward solving a search problem. In this paper, we present a method by which\\nbacktrack points can be moved deeper in the search space, thereby avoiding this\\ndifficulty. The technique developed is a variant of dependency-directed\\nbacktracking that uses only polynomial space while still providing useful\\ncontrol information and retaining the completeness guarantees provided by\\nearlier approaches.', 'authors': ['M. L. Ginsberg'], 'arxiv_id': '9308101v1', 'url': 'http://arxiv.org/abs/cs/9308101v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9308101v1'}, {'title': 'A Market-Oriented Programming Environment and its Application to\\n  Distributed Multicommodity Flow Problems', 'summary': 'Market price systems constitute a well-understood class of mechanisms that\\nunder certain conditions provide effective decentralization of decision making\\nwith minimal communication overhead. In a market-oriented programming approach\\nto distributed problem solving, we derive the activities and resource\\nallocations for a set of computational agents by computing the competitive\\nequilibrium of an artificial economy. WALRAS provides basic constructs for\\ndefining computational market structures, and protocols for deriving their\\ncorresponding price equilibria. In a particular realization of this approach\\nfor a form of multicommodity flow problem, we see that careful construction of\\nthe decision process according to economic principles can lead to efficient\\ndistributed resource allocation, and that the behavior of the system can be\\nmeaningfully analyzed in economic terms.', 'authors': ['M. P. Wellman'], 'arxiv_id': '9308102v1', 'url': 'http://arxiv.org/abs/cs/9308102v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9308102v1'}, {'title': 'An Empirical Analysis of Search in GSAT', 'summary': \"We describe an extensive study of search in GSAT, an approximation procedure\\nfor propositional satisfiability. GSAT performs greedy hill-climbing on the\\nnumber of satisfied clauses in a truth assignment. Our experiments provide a\\nmore complete picture of GSAT's search than previous accounts. We describe in\\ndetail the two phases of search: rapid hill-climbing followed by a long plateau\\nsearch. We demonstrate that when applied to randomly generated 3SAT problems,\\nthere is a very simple scaling with problem size for both the mean number of\\nsatisfied clauses and the mean branching rate. Our results allow us to make\\ndetailed numerical conjectures about the length of the hill-climbing phase, the\\naverage gradient of this phase, and to conjecture that both the average score\\nand average branching rate decay exponentially during plateau search. We end by\\nshowing how these results can be used to direct future theoretical analysis.\\nThis work provides a case study of how computer experiments can be used to\\nimprove understanding of the theoretical properties of algorithms.\", 'authors': ['I. P. Gent', 'T. Walsh'], 'arxiv_id': '9309101v1', 'url': 'http://arxiv.org/abs/cs/9309101v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9309101v1'}, {'title': 'The Difficulties of Learning Logic Programs with Cut', 'summary': 'As real logic programmers normally use cut (!), an effective learning\\nprocedure for logic programs should be able to deal with it. Because the cut\\npredicate has only a procedural meaning, clauses containing cut cannot be\\nlearned using an extensional evaluation method, as is done in most learning\\nsystems. On the other hand, searching a space of possible programs (instead of\\na space of independent clauses) is unfeasible. An alternative solution is to\\ngenerate first a candidate base program which covers the positive examples, and\\nthen make it consistent by inserting cut where appropriate. The problem of\\nlearning programs with cut has not been investigated before and this seems to\\nbe a natural and reasonable approach. We generalize this scheme and investigate\\nthe difficulties that arise. Some of the major shortcomings are actually\\ncaused, in general, by the need for intensional evaluation. As a conclusion,\\nthe analysis of this paper suggests, on precise and technical grounds, that\\nlearning cut is difficult, and current induction techniques should probably be\\nrestricted to purely declarative logic languages.', 'authors': ['F. Bergadano', 'D. Gunetti', 'U. Trinchero'], 'arxiv_id': '9311101v1', 'url': 'http://arxiv.org/abs/cs/9311101v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9311101v1'}, {'title': 'Software Agents: Completing Patterns and Constructing User Interfaces', 'summary': \"To support the goal of allowing users to record and retrieve information,\\nthis paper describes an interactive note-taking system for pen-based computers\\nwith two distinctive features. First, it actively predicts what the user is\\ngoing to write. Second, it automatically constructs a custom, button-box user\\ninterface on request. The system is an example of a learning-apprentice\\nsoftware- agent. A machine learning component characterizes the syntax and\\nsemantics of the user's information. A performance system uses this learned\\ninformation to generate completion strings and construct a user interface.\\nDescription of Online Appendix: People like to record information. Doing this\\non paper is initially efficient, but lacks flexibility. Recording information\\non a computer is less efficient but more powerful. In our new note taking\\nsoftwre, the user records information directly on a computer. Behind the\\ninterface, an agent acts for the user. To help, it provides defaults and\\nconstructs a custom user interface. The demonstration is a QuickTime movie of\\nthe note taking agent in action. The file is a binhexed self-extracting\\narchive. Macintosh utilities for binhex are available from\\nmac.archive.umich.edu. QuickTime is available from ftp.apple.com in the\\ndts/mac/sys.soft/quicktime.\", 'authors': ['J. C. Schlimmer', 'L. A. Hermens'], 'arxiv_id': '9311102v1', 'url': 'http://arxiv.org/abs/cs/9311102v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9311102v1'}, {'title': 'Decidable Reasoning in Terminological Knowledge Representation Systems', 'summary': 'Terminological knowledge representation systems (TKRSs) are tools for\\ndesigning and using knowledge bases that make use of terminological languages\\n(or concept languages). We analyze from a theoretical point of view a TKRS\\nwhose capabilities go beyond the ones of presently available TKRSs. The new\\nfeatures studied, often required in practical applications, can be summarized\\nin three main points. First, we consider a highly expressive terminological\\nlanguage, called ALCNR, including general complements of concepts, number\\nrestrictions and role conjunction. Second, we allow to express inclusion\\nstatements between general concepts, and terminological cycles as a particular\\ncase. Third, we prove the decidability of a number of desirable TKRS-deduction\\nservices (like satisfiability, subsumption and instance checking) through a\\nsound, complete and terminating calculus for reasoning in ALCNR-knowledge\\nbases. Our calculus extends the general technique of constraint systems. As a\\nbyproduct of the proof, we get also the result that inclusion statements in\\nALCNR can be simulated by terminological cycles, if descriptive semantics is\\nadopted.', 'authors': ['M. Buchheit', 'F. M. Donini', 'A. Schaerf'], 'arxiv_id': '9312101v1', 'url': 'http://arxiv.org/abs/cs/9312101v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9312101v1'}, {'title': 'Teleo-Reactive Programs for Agent Control', 'summary': 'A formalism is presented for computing and organizing actions for autonomous\\nagents in dynamic environments. We introduce the notion of teleo-reactive (T-R)\\nprograms whose execution entails the construction of circuitry for the\\ncontinuous computation of the parameters and conditions on which agent action\\nis based. In addition to continuous feedback, T-R programs support parameter\\nbinding and recursion. A primary difference between T-R programs and many other\\ncircuit-based systems is that the circuitry of T-R programs is more compact; it\\nis constructed at run time and thus does not have to anticipate all the\\ncontingencies that might arise over all possible runs. In addition, T-R\\nprograms are intuitive and easy to write and are written in a form that is\\ncompatible with automatic planning and learning methods. We briefly describe\\nsome experimental applications of T-R programs in the control of simulated and\\nactual mobile robots.', 'authors': ['N. Nilsson'], 'arxiv_id': '9401101v1', 'url': 'http://arxiv.org/abs/cs/9401101v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9401101v1'}, {'title': 'Learning the Past Tense of English Verbs: The Symbolic Pattern\\n  Associator vs. Connectionist Models', 'summary': 'Learning the past tense of English verbs - a seemingly minor aspect of\\nlanguage acquisition - has generated heated debates since 1986, and has become\\na landmark task for testing the adequacy of cognitive modeling. Several\\nartificial neural networks (ANNs) have been implemented, and a challenge for\\nbetter symbolic models has been posed. In this paper, we present a\\ngeneral-purpose Symbolic Pattern Associator (SPA) based upon the decision-tree\\nlearning algorithm ID3. We conduct extensive head-to-head comparisons on the\\ngeneralization ability between ANN models and the SPA under different\\nrepresentations. We conclude that the SPA generalizes the past tense of unseen\\nverbs better than ANN models by a wide margin, and we offer insights as to why\\nthis should be the case. We also discuss a new default strategy for\\ndecision-tree learning algorithms.', 'authors': ['C. X. Ling'], 'arxiv_id': '9402101v1', 'url': 'http://arxiv.org/abs/cs/9402101v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9402101v1'}, {'title': 'Substructure Discovery Using Minimum Description Length and Background\\n  Knowledge', 'summary': \"The ability to identify interesting and repetitive substructures is an\\nessential component to discovering knowledge in structural data. We describe a\\nnew version of our SUBDUE substructure discovery system based on the minimum\\ndescription length principle. The SUBDUE system discovers substructures that\\ncompress the original data and represent structural concepts in the data. By\\nreplacing previously-discovered substructures in the data, multiple passes of\\nSUBDUE produce a hierarchical description of the structural regularities in the\\ndata. SUBDUE uses a computationally-bounded inexact graph match that identifies\\nsimilar, but not identical, instances of a substructure and finds an\\napproximate measure of closeness of two substructures when under computational\\nconstraints. In addition to the minimum description length principle, other\\nbackground knowledge can be used by SUBDUE to guide the search towards more\\nappropriate substructures. Experiments in a variety of domains demonstrate\\nSUBDUE's ability to find substructures capable of compressing the original data\\nand to discover structural concepts important to the domain. Description of\\nOnline Appendix: This is a compressed tar file containing the SUBDUE discovery\\nsystem, written in C. The program accepts as input databases represented in\\ngraph form, and will output discovered substructures with their corresponding\\nvalue.\", 'authors': ['D. J. Cook', 'L. B. Holder'], 'arxiv_id': '9402102v1', 'url': 'http://arxiv.org/abs/cs/9402102v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9402102v1'}, {'title': 'Bias-Driven Revision of Logical Domain Theories', 'summary': \"The theory revision problem is the problem of how best to go about revising a\\ndeficient domain theory using information contained in examples that expose\\ninaccuracies. In this paper we present our approach to the theory revision\\nproblem for propositional domain theories. The approach described here, called\\nPTR, uses probabilities associated with domain theory elements to numerically\\ntrack the ``flow'' of proof through the theory. This allows us to measure the\\nprecise role of a clause or literal in allowing or preventing a (desired or\\nundesired) derivation for a given example. This information is used to\\nefficiently locate and repair flawed elements of the theory. PTR is proved to\\nconverge to a theory which correctly classifies all examples, and shown\\nexperimentally to be fast and accurate even for deep theories.\", 'authors': ['M. Koppel', 'R. Feldman', 'A. M. Segre'], 'arxiv_id': '9402103v1', 'url': 'http://arxiv.org/abs/cs/9402103v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9402103v1'}, {'title': \"Exploring the Decision Forest: An Empirical Investigation of Occam's\\n  Razor in Decision Tree Induction\", 'summary': 'We report on a series of experiments in which all decision trees consistent\\nwith the training data are constructed. These experiments were run to gain an\\nunderstanding of the properties of the set of consistent decision trees and the\\nfactors that affect the accuracy of individual trees. In particular, we\\ninvestigated the relationship between the size of a decision tree consistent\\nwith some training data and the accuracy of the tree on test data. The\\nexperiments were performed on a massively parallel Maspar computer. The results\\nof the experiments on several artificial and two real world problems indicate\\nthat, for many of the problems investigated, smaller consistent decision trees\\nare on average less accurate than the average accuracy of slightly larger\\ntrees.', 'authors': ['P. M. Murphy', 'M. J. Pazzani'], 'arxiv_id': '9403101v1', 'url': 'http://arxiv.org/abs/cs/9403101v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9403101v1'}, {'title': 'A Semantics and Complete Algorithm for Subsumption in the CLASSIC\\n  Description Logic', 'summary': 'This paper analyzes the correctness of the subsumption algorithm used in\\nCLASSIC, a description logic-based knowledge representation system that is\\nbeing used in practical applications. In order to deal efficiently with\\nindividuals in CLASSIC descriptions, the developers have had to use an\\nalgorithm that is incomplete with respect to the standard, model-theoretic\\nsemantics for description logics. We provide a variant semantics for\\ndescriptions with respect to which the current implementation is complete, and\\nwhich can be independently motivated. The soundness and completeness of the\\npolynomial-time subsumption algorithm is established using description graphs,\\nwhich are an abstracted version of the implementation structures used in\\nCLASSIC, and are of independent interest.', 'authors': ['A. Borgida', 'P. F. Patel-Schneider'], 'arxiv_id': '9406101v1', 'url': 'http://arxiv.org/abs/cs/9406101v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9406101v1'}, {'title': 'Applying GSAT to Non-Clausal Formulas', 'summary': \"In this paper we describe how to modify GSAT so that it can be applied to\\nnon-clausal formulas. The idea is to use a particular ``score'' function which\\ngives the number of clauses of the CNF conversion of a formula which are false\\nunder a given truth assignment. Its value is computed in linear time, without\\nconstructing the CNF conversion itself. The proposed methodology applies to\\nmost of the variants of GSAT proposed so far.\", 'authors': ['R. Sebastiani'], 'arxiv_id': '9406102v1', 'url': 'http://arxiv.org/abs/cs/9406102v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9406102v1'}, {'title': 'Random Worlds and Maximum Entropy', 'summary': 'Given a knowledge base KB containing first-order and statistical facts, we\\nconsider a principled method, called the random-worlds method, for computing a\\ndegree of belief that some formula Phi holds given KB. If we are reasoning\\nabout a world or system consisting of N individuals, then we can consider all\\npossible worlds, or first-order models, with domain {1,...,N} that satisfy KB,\\nand compute the fraction of them in which Phi is true. We define the degree of\\nbelief to be the asymptotic value of this fraction as N grows large. We show\\nthat when the vocabulary underlying Phi and KB uses constants and unary\\npredicates only, we can naturally associate an entropy with each world. As N\\ngrows larger, there are many more worlds with higher entropy. Therefore, we can\\nuse a maximum-entropy computation to compute the degree of belief. This result\\nis in a similar spirit to previous work in physics and artificial intelligence,\\nbut is far more general. Of equal interest to the result itself are the\\nlimitations on its scope. Most importantly, the restriction to unary predicates\\nseems necessary. Although the random-worlds method makes sense in general, the\\nconnection to maximum entropy seems to disappear in the non-unary case. These\\nobservations suggest unexpected limitations to the applicability of\\nmaximum-entropy methods.', 'authors': ['A. J. Grove', 'J. Y. Halpern', 'D. Koller'], 'arxiv_id': '9408101v1', 'url': 'http://arxiv.org/abs/cs/9408101v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9408101v1'}, {'title': 'Pattern Matching and Discourse Processing in Information Extraction from\\n  Japanese Text', 'summary': 'Information extraction is the task of automatically picking up information of\\ninterest from an unconstrained text. Information of interest is usually\\nextracted in two steps. First, sentence level processing locates relevant\\npieces of information scattered throughout the text; second, discourse\\nprocessing merges coreferential information to generate the output. In the\\nfirst step, pieces of information are locally identified without recognizing\\nany relationships among them. A key word search or simple pattern search can\\nachieve this purpose. The second step requires deeper knowledge in order to\\nunderstand relationships among separately identified pieces of information.\\nPrevious information extraction systems focused on the first step, partly\\nbecause they were not required to link up each piece of information with other\\npieces. To link the extracted pieces of information and map them onto a\\nstructured output format, complex discourse processing is essential. This paper\\nreports on a Japanese information extraction system that merges information\\nusing a pattern matcher and discourse processor. Evaluation results show a high\\nlevel of system performance which approaches human performance.', 'authors': ['T. Kitani', 'Y. Eriguchi', 'M. Hara'], 'arxiv_id': '9408102v1', 'url': 'http://arxiv.org/abs/cs/9408102v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9408102v1'}, {'title': 'A System for Induction of Oblique Decision Trees', 'summary': \"This article describes a new system for induction of oblique decision trees.\\nThis system, OC1, combines deterministic hill-climbing with two forms of\\nrandomization to find a good oblique split (in the form of a hyperplane) at\\neach node of a decision tree. Oblique decision tree methods are tuned\\nespecially for domains in which the attributes are numeric, although they can\\nbe adapted to symbolic or mixed symbolic/numeric attributes. We present\\nextensive empirical studies, using both real and artificial data, that analyze\\nOC1's ability to construct oblique trees that are smaller and more accurate\\nthan their axis-parallel counterparts. We also examine the benefits of\\nrandomization for the construction of oblique decision trees.\", 'authors': ['S. K. Murthy', 'S. Kasif', 'S. Salzberg'], 'arxiv_id': '9408103v1', 'url': 'http://arxiv.org/abs/cs/9408103v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9408103v1'}, {'title': 'On Planning while Learning', 'summary': 'This paper introduces a framework for Planning while Learning where an agent\\nis given a goal to achieve in an environment whose behavior is only partially\\nknown to the agent. We discuss the tractability of various plan-design\\nprocesses. We show that for a large natural class of Planning while Learning\\nsystems, a plan can be presented and verified in a reasonable time. However,\\ncoming up algorithmically with a plan, even for simple classes of systems is\\napparently intractable. We emphasize the role of off-line plan-design\\nprocesses, and show that, in most natural cases, the verification (projection)\\npart can be carried out in an efficient algorithmic manner.', 'authors': ['S. Safra', 'M. Tennenholtz'], 'arxiv_id': '9409101v1', 'url': 'http://arxiv.org/abs/cs/9409101v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9409101v1'}, {'title': 'Wrap-Up: a Trainable Discourse Module for Information Extraction', 'summary': 'The vast amounts of on-line text now available have led to renewed interest\\nin information extraction (IE) systems that analyze unrestricted text,\\nproducing a structured representation of selected information from the text.\\nThis paper presents a novel approach that uses machine learning to acquire\\nknowledge for some of the higher level IE processing. Wrap-Up is a trainable IE\\ndiscourse component that makes intersentential inferences and identifies\\nlogical relations among information extracted from the text. Previous\\ncorpus-based approaches were limited to lower level processing such as\\npart-of-speech tagging, lexical disambiguation, and dictionary construction.\\nWrap-Up is fully trainable, and not only automatically decides what classifiers\\nare needed, but even derives the feature set for each classifier automatically.\\nPerformance equals that of a partially trainable discourse module requiring\\nmanual customization for each domain.', 'authors': ['S. Soderland', 'Lehnert. W'], 'arxiv_id': '9412101v1', 'url': 'http://arxiv.org/abs/cs/9412101v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9412101v1'}, {'title': 'Operations for Learning with Graphical Models', 'summary': 'This paper is a multidisciplinary review of empirical, statistical learning\\nfrom a graphical model perspective. Well-known examples of graphical models\\ninclude Bayesian networks, directed graphs representing a Markov chain, and\\nundirected networks representing a Markov field. These graphical models are\\nextended to model data analysis and empirical learning using the notation of\\nplates. Graphical operations for simplifying and manipulating a problem are\\nprovided including decomposition, differentiation, and the manipulation of\\nprobability models from the exponential family. Two standard algorithm schemas\\nfor learning are reviewed in a graphical framework: Gibbs sampling and the\\nexpectation maximization algorithm. Using these operations and schemas, some\\npopular algorithms can be synthesized from their graphical specification. This\\nincludes versions of linear regression, techniques for feed-forward networks,\\nand learning Gaussian and discrete Bayesian networks from data. The paper\\nconcludes by sketching some implications for data analysis and summarizing how\\nsome popular algorithms fall within the framework presented. The main original\\ncontributions here are the decomposition techniques and the demonstration that\\ngraphical models provide a framework for understanding and developing complex\\nlearning algorithms.', 'authors': ['W. L. Buntine'], 'arxiv_id': '9412102v1', 'url': 'http://arxiv.org/abs/cs/9412102v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9412102v1'}, {'title': 'Total-Order and Partial-Order Planning: A Comparative Analysis', 'summary': 'For many years, the intuitions underlying partial-order planning were largely\\ntaken for granted. Only in the past few years has there been renewed interest\\nin the fundamental principles underlying this paradigm. In this paper, we\\npresent a rigorous comparative analysis of partial-order and total-order\\nplanning by focusing on two specific planners that can be directly compared. We\\nshow that there are some subtle assumptions that underly the wide-spread\\nintuitions regarding the supposed efficiency of partial-order planning. For\\ninstance, the superiority of partial-order planning can depend critically upon\\nthe search strategy and the structure of the search space. Understanding the\\nunderlying assumptions is crucial for constructing efficient planners.', 'authors': ['S. Minton', 'J. Bresina', 'M. Drummond'], 'arxiv_id': '9412103v1', 'url': 'http://arxiv.org/abs/cs/9412103v1', 'pdf_link': 'http://arxiv.org/pdf/cs/9412103v1'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = \"files/arxiv_dataset.json\"\n",
    "with open(file_name, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>url</th>\n",
       "      <th>pdf_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decidable Reasoning in Terminological Knowledg...</td>\n",
       "      <td>Terminological knowledge representation system...</td>\n",
       "      <td>[M. Buchheit, F. M. Donini, A. Schaerf]</td>\n",
       "      <td>9312101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9312101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9312101v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Teleo-Reactive Programs for Agent Control</td>\n",
       "      <td>A formalism is presented for computing and org...</td>\n",
       "      <td>[N. Nilsson]</td>\n",
       "      <td>9401101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9401101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9401101v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Operations for Learning with Graphical Models</td>\n",
       "      <td>This paper is a multidisciplinary review of em...</td>\n",
       "      <td>[W. L. Buntine]</td>\n",
       "      <td>9412102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9412102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9412102v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wrap-Up: a Trainable Discourse Module for Info...</td>\n",
       "      <td>The vast amounts of on-line text now available...</td>\n",
       "      <td>[S. Soderland, Lehnert. W]</td>\n",
       "      <td>9412101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9412101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9412101v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dynamic Backtracking</td>\n",
       "      <td>Because of their occasional need to return to ...</td>\n",
       "      <td>[M. L. Ginsberg]</td>\n",
       "      <td>9308101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9308101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9308101v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "5   Decidable Reasoning in Terminological Knowledg...   \n",
       "6           Teleo-Reactive Programs for Agent Control   \n",
       "18      Operations for Learning with Graphical Models   \n",
       "17  Wrap-Up: a Trainable Discourse Module for Info...   \n",
       "0                                Dynamic Backtracking   \n",
       "\n",
       "                                              summary  \\\n",
       "5   Terminological knowledge representation system...   \n",
       "6   A formalism is presented for computing and org...   \n",
       "18  This paper is a multidisciplinary review of em...   \n",
       "17  The vast amounts of on-line text now available...   \n",
       "0   Because of their occasional need to return to ...   \n",
       "\n",
       "                                    authors   arxiv_id  \\\n",
       "5   [M. Buchheit, F. M. Donini, A. Schaerf]  9312101v1   \n",
       "6                              [N. Nilsson]  9401101v1   \n",
       "18                          [W. L. Buntine]  9412102v1   \n",
       "17               [S. Soderland, Lehnert. W]  9412101v1   \n",
       "0                          [M. L. Ginsberg]  9308101v1   \n",
       "\n",
       "                                  url                           pdf_link  \n",
       "5   http://arxiv.org/abs/cs/9312101v1  http://arxiv.org/pdf/cs/9312101v1  \n",
       "6   http://arxiv.org/abs/cs/9401101v1  http://arxiv.org/pdf/cs/9401101v1  \n",
       "18  http://arxiv.org/abs/cs/9412102v1  http://arxiv.org/pdf/cs/9412102v1  \n",
       "17  http://arxiv.org/abs/cs/9412101v1  http://arxiv.org/pdf/cs/9412101v1  \n",
       "0   http://arxiv.org/abs/cs/9308101v1  http://arxiv.org/pdf/cs/9308101v1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def download_pdfs(df, download_folder=\"files\"):\n",
    "    \"\"\"\n",
    "    Downloads PDFs from URLs listed in the DataFrame and saves them to a specified folder. \n",
    "    The file names are stored in a new column 'pdf_file_name' in the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing a 'pdf_link' column with URLs to download.\n",
    "        download_folder (str): Path to the folder where PDFs will be saved (default is 'files').\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The original DataFrame with an additional 'pdf_file_name' column containing \n",
    "                      the paths of the downloaded PDF files or None if the download failed.\"\"\"\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "\n",
    "    pdf_file_names = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        pdf_link = row[\"pdf_link\"]\n",
    "       \n",
    "        try:\n",
    "            response = requests.get(pdf_link)\n",
    "            response.raise_for_status()\n",
    "        \n",
    "            file_name = os.path.join(download_folder, pdf_link.split(\"/\")[-1]) + \".pdf\"\n",
    "            pdf_file_names.append(file_name)\n",
    "\n",
    "            with open(file_name, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            \n",
    "            print(f\"PDF downloaded successfully and saved as {file_name}\")\n",
    "        \n",
    "        except requests.exceptions.RequestException as e:\n",
    "           print(f\"Failed to download the PDF: {e}\")\n",
    "           pdf_file_names.append(None)\n",
    "    \n",
    "    df[\"pdf_file_name\"] = pdf_file_names\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded successfully and saved as files/9308101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9308102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9309101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9311101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9311102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9312101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9401101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9402101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9402102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9402103v1.pdf\n",
      "PDF downloaded successfully and saved as files/9403101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9406101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9406102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9408101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9408102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9408103v1.pdf\n",
      "PDF downloaded successfully and saved as files/9409101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9412101v1.pdf\n",
      "PDF downloaded successfully and saved as files/9412102v1.pdf\n",
      "PDF downloaded successfully and saved as files/9412103v1.pdf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>url</th>\n",
       "      <th>pdf_link</th>\n",
       "      <th>pdf_file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dynamic Backtracking</td>\n",
       "      <td>Because of their occasional need to return to ...</td>\n",
       "      <td>[M. L. Ginsberg]</td>\n",
       "      <td>9308101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9308101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9308101v1</td>\n",
       "      <td>files/9308101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Market-Oriented Programming Environment and ...</td>\n",
       "      <td>Market price systems constitute a well-underst...</td>\n",
       "      <td>[M. P. Wellman]</td>\n",
       "      <td>9308102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9308102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9308102v1</td>\n",
       "      <td>files/9308102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An Empirical Analysis of Search in GSAT</td>\n",
       "      <td>We describe an extensive study of search in GS...</td>\n",
       "      <td>[I. P. Gent, T. Walsh]</td>\n",
       "      <td>9309101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9309101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9309101v1</td>\n",
       "      <td>files/9309101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Difficulties of Learning Logic Programs wi...</td>\n",
       "      <td>As real logic programmers normally use cut (!)...</td>\n",
       "      <td>[F. Bergadano, D. Gunetti, U. Trinchero]</td>\n",
       "      <td>9311101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9311101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9311101v1</td>\n",
       "      <td>files/9311101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Software Agents: Completing Patterns and Const...</td>\n",
       "      <td>To support the goal of allowing users to recor...</td>\n",
       "      <td>[J. C. Schlimmer, L. A. Hermens]</td>\n",
       "      <td>9311102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9311102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9311102v1</td>\n",
       "      <td>files/9311102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decidable Reasoning in Terminological Knowledg...</td>\n",
       "      <td>Terminological knowledge representation system...</td>\n",
       "      <td>[M. Buchheit, F. M. Donini, A. Schaerf]</td>\n",
       "      <td>9312101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9312101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9312101v1</td>\n",
       "      <td>files/9312101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Teleo-Reactive Programs for Agent Control</td>\n",
       "      <td>A formalism is presented for computing and org...</td>\n",
       "      <td>[N. Nilsson]</td>\n",
       "      <td>9401101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9401101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9401101v1</td>\n",
       "      <td>files/9401101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Learning the Past Tense of English Verbs: The ...</td>\n",
       "      <td>Learning the past tense of English verbs - a s...</td>\n",
       "      <td>[C. X. Ling]</td>\n",
       "      <td>9402101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9402101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9402101v1</td>\n",
       "      <td>files/9402101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Substructure Discovery Using Minimum Descripti...</td>\n",
       "      <td>The ability to identify interesting and repeti...</td>\n",
       "      <td>[D. J. Cook, L. B. Holder]</td>\n",
       "      <td>9402102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9402102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9402102v1</td>\n",
       "      <td>files/9402102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bias-Driven Revision of Logical Domain Theories</td>\n",
       "      <td>The theory revision problem is the problem of ...</td>\n",
       "      <td>[M. Koppel, R. Feldman, A. M. Segre]</td>\n",
       "      <td>9402103v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9402103v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9402103v1</td>\n",
       "      <td>files/9402103v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Exploring the Decision Forest: An Empirical In...</td>\n",
       "      <td>We report on a series of experiments in which ...</td>\n",
       "      <td>[P. M. Murphy, M. J. Pazzani]</td>\n",
       "      <td>9403101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9403101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9403101v1</td>\n",
       "      <td>files/9403101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A Semantics and Complete Algorithm for Subsump...</td>\n",
       "      <td>This paper analyzes the correctness of the sub...</td>\n",
       "      <td>[A. Borgida, P. F. Patel-Schneider]</td>\n",
       "      <td>9406101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9406101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9406101v1</td>\n",
       "      <td>files/9406101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Applying GSAT to Non-Clausal Formulas</td>\n",
       "      <td>In this paper we describe how to modify GSAT s...</td>\n",
       "      <td>[R. Sebastiani]</td>\n",
       "      <td>9406102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9406102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9406102v1</td>\n",
       "      <td>files/9406102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Worlds and Maximum Entropy</td>\n",
       "      <td>Given a knowledge base KB containing first-ord...</td>\n",
       "      <td>[A. J. Grove, J. Y. Halpern, D. Koller]</td>\n",
       "      <td>9408101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9408101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9408101v1</td>\n",
       "      <td>files/9408101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pattern Matching and Discourse Processing in I...</td>\n",
       "      <td>Information extraction is the task of automati...</td>\n",
       "      <td>[T. Kitani, Y. Eriguchi, M. Hara]</td>\n",
       "      <td>9408102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9408102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9408102v1</td>\n",
       "      <td>files/9408102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A System for Induction of Oblique Decision Trees</td>\n",
       "      <td>This article describes a new system for induct...</td>\n",
       "      <td>[S. K. Murthy, S. Kasif, S. Salzberg]</td>\n",
       "      <td>9408103v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9408103v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9408103v1</td>\n",
       "      <td>files/9408103v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>On Planning while Learning</td>\n",
       "      <td>This paper introduces a framework for Planning...</td>\n",
       "      <td>[S. Safra, M. Tennenholtz]</td>\n",
       "      <td>9409101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9409101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9409101v1</td>\n",
       "      <td>files/9409101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wrap-Up: a Trainable Discourse Module for Info...</td>\n",
       "      <td>The vast amounts of on-line text now available...</td>\n",
       "      <td>[S. Soderland, Lehnert. W]</td>\n",
       "      <td>9412101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9412101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9412101v1</td>\n",
       "      <td>files/9412101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Operations for Learning with Graphical Models</td>\n",
       "      <td>This paper is a multidisciplinary review of em...</td>\n",
       "      <td>[W. L. Buntine]</td>\n",
       "      <td>9412102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9412102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9412102v1</td>\n",
       "      <td>files/9412102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Total-Order and Partial-Order Planning: A Comp...</td>\n",
       "      <td>For many years, the intuitions underlying part...</td>\n",
       "      <td>[S. Minton, J. Bresina, M. Drummond]</td>\n",
       "      <td>9412103v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9412103v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9412103v1</td>\n",
       "      <td>files/9412103v1.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                                Dynamic Backtracking   \n",
       "1   A Market-Oriented Programming Environment and ...   \n",
       "2             An Empirical Analysis of Search in GSAT   \n",
       "3   The Difficulties of Learning Logic Programs wi...   \n",
       "4   Software Agents: Completing Patterns and Const...   \n",
       "5   Decidable Reasoning in Terminological Knowledg...   \n",
       "6           Teleo-Reactive Programs for Agent Control   \n",
       "7   Learning the Past Tense of English Verbs: The ...   \n",
       "8   Substructure Discovery Using Minimum Descripti...   \n",
       "9     Bias-Driven Revision of Logical Domain Theories   \n",
       "10  Exploring the Decision Forest: An Empirical In...   \n",
       "11  A Semantics and Complete Algorithm for Subsump...   \n",
       "12              Applying GSAT to Non-Clausal Formulas   \n",
       "13                  Random Worlds and Maximum Entropy   \n",
       "14  Pattern Matching and Discourse Processing in I...   \n",
       "15   A System for Induction of Oblique Decision Trees   \n",
       "16                         On Planning while Learning   \n",
       "17  Wrap-Up: a Trainable Discourse Module for Info...   \n",
       "18      Operations for Learning with Graphical Models   \n",
       "19  Total-Order and Partial-Order Planning: A Comp...   \n",
       "\n",
       "                                              summary  \\\n",
       "0   Because of their occasional need to return to ...   \n",
       "1   Market price systems constitute a well-underst...   \n",
       "2   We describe an extensive study of search in GS...   \n",
       "3   As real logic programmers normally use cut (!)...   \n",
       "4   To support the goal of allowing users to recor...   \n",
       "5   Terminological knowledge representation system...   \n",
       "6   A formalism is presented for computing and org...   \n",
       "7   Learning the past tense of English verbs - a s...   \n",
       "8   The ability to identify interesting and repeti...   \n",
       "9   The theory revision problem is the problem of ...   \n",
       "10  We report on a series of experiments in which ...   \n",
       "11  This paper analyzes the correctness of the sub...   \n",
       "12  In this paper we describe how to modify GSAT s...   \n",
       "13  Given a knowledge base KB containing first-ord...   \n",
       "14  Information extraction is the task of automati...   \n",
       "15  This article describes a new system for induct...   \n",
       "16  This paper introduces a framework for Planning...   \n",
       "17  The vast amounts of on-line text now available...   \n",
       "18  This paper is a multidisciplinary review of em...   \n",
       "19  For many years, the intuitions underlying part...   \n",
       "\n",
       "                                     authors   arxiv_id  \\\n",
       "0                           [M. L. Ginsberg]  9308101v1   \n",
       "1                            [M. P. Wellman]  9308102v1   \n",
       "2                     [I. P. Gent, T. Walsh]  9309101v1   \n",
       "3   [F. Bergadano, D. Gunetti, U. Trinchero]  9311101v1   \n",
       "4           [J. C. Schlimmer, L. A. Hermens]  9311102v1   \n",
       "5    [M. Buchheit, F. M. Donini, A. Schaerf]  9312101v1   \n",
       "6                               [N. Nilsson]  9401101v1   \n",
       "7                               [C. X. Ling]  9402101v1   \n",
       "8                 [D. J. Cook, L. B. Holder]  9402102v1   \n",
       "9       [M. Koppel, R. Feldman, A. M. Segre]  9402103v1   \n",
       "10             [P. M. Murphy, M. J. Pazzani]  9403101v1   \n",
       "11       [A. Borgida, P. F. Patel-Schneider]  9406101v1   \n",
       "12                           [R. Sebastiani]  9406102v1   \n",
       "13   [A. J. Grove, J. Y. Halpern, D. Koller]  9408101v1   \n",
       "14         [T. Kitani, Y. Eriguchi, M. Hara]  9408102v1   \n",
       "15     [S. K. Murthy, S. Kasif, S. Salzberg]  9408103v1   \n",
       "16                [S. Safra, M. Tennenholtz]  9409101v1   \n",
       "17                [S. Soderland, Lehnert. W]  9412101v1   \n",
       "18                           [W. L. Buntine]  9412102v1   \n",
       "19      [S. Minton, J. Bresina, M. Drummond]  9412103v1   \n",
       "\n",
       "                                  url                           pdf_link  \\\n",
       "0   http://arxiv.org/abs/cs/9308101v1  http://arxiv.org/pdf/cs/9308101v1   \n",
       "1   http://arxiv.org/abs/cs/9308102v1  http://arxiv.org/pdf/cs/9308102v1   \n",
       "2   http://arxiv.org/abs/cs/9309101v1  http://arxiv.org/pdf/cs/9309101v1   \n",
       "3   http://arxiv.org/abs/cs/9311101v1  http://arxiv.org/pdf/cs/9311101v1   \n",
       "4   http://arxiv.org/abs/cs/9311102v1  http://arxiv.org/pdf/cs/9311102v1   \n",
       "5   http://arxiv.org/abs/cs/9312101v1  http://arxiv.org/pdf/cs/9312101v1   \n",
       "6   http://arxiv.org/abs/cs/9401101v1  http://arxiv.org/pdf/cs/9401101v1   \n",
       "7   http://arxiv.org/abs/cs/9402101v1  http://arxiv.org/pdf/cs/9402101v1   \n",
       "8   http://arxiv.org/abs/cs/9402102v1  http://arxiv.org/pdf/cs/9402102v1   \n",
       "9   http://arxiv.org/abs/cs/9402103v1  http://arxiv.org/pdf/cs/9402103v1   \n",
       "10  http://arxiv.org/abs/cs/9403101v1  http://arxiv.org/pdf/cs/9403101v1   \n",
       "11  http://arxiv.org/abs/cs/9406101v1  http://arxiv.org/pdf/cs/9406101v1   \n",
       "12  http://arxiv.org/abs/cs/9406102v1  http://arxiv.org/pdf/cs/9406102v1   \n",
       "13  http://arxiv.org/abs/cs/9408101v1  http://arxiv.org/pdf/cs/9408101v1   \n",
       "14  http://arxiv.org/abs/cs/9408102v1  http://arxiv.org/pdf/cs/9408102v1   \n",
       "15  http://arxiv.org/abs/cs/9408103v1  http://arxiv.org/pdf/cs/9408103v1   \n",
       "16  http://arxiv.org/abs/cs/9409101v1  http://arxiv.org/pdf/cs/9409101v1   \n",
       "17  http://arxiv.org/abs/cs/9412101v1  http://arxiv.org/pdf/cs/9412101v1   \n",
       "18  http://arxiv.org/abs/cs/9412102v1  http://arxiv.org/pdf/cs/9412102v1   \n",
       "19  http://arxiv.org/abs/cs/9412103v1  http://arxiv.org/pdf/cs/9412103v1   \n",
       "\n",
       "          pdf_file_name  \n",
       "0   files/9308101v1.pdf  \n",
       "1   files/9308102v1.pdf  \n",
       "2   files/9309101v1.pdf  \n",
       "3   files/9311101v1.pdf  \n",
       "4   files/9311102v1.pdf  \n",
       "5   files/9312101v1.pdf  \n",
       "6   files/9401101v1.pdf  \n",
       "7   files/9402101v1.pdf  \n",
       "8   files/9402102v1.pdf  \n",
       "9   files/9402103v1.pdf  \n",
       "10  files/9403101v1.pdf  \n",
       "11  files/9406101v1.pdf  \n",
       "12  files/9406102v1.pdf  \n",
       "13  files/9408101v1.pdf  \n",
       "14  files/9408102v1.pdf  \n",
       "15  files/9408103v1.pdf  \n",
       "16  files/9409101v1.pdf  \n",
       "17  files/9412101v1.pdf  \n",
       "18  files/9412102v1.pdf  \n",
       "19  files/9412103v1.pdf  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = download_pdfs(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def load_and_chunk_pdf(pdf_file_name, chunk_size=512):\n",
    "    \"\"\"\n",
    "    Loads a PDF file and splits its content into chunks of a specified size.\n",
    "\n",
    "    Args:\n",
    "        file (str): Path to the PDF file to be loaded.\n",
    "        chunk_size (int): The maximum size of each chunk in characters (default is 512).\n",
    "\n",
    "    Returns:\n",
    "        List[Document]: A list of document chunks.\n",
    "    \"\"\"\n",
    "    print(f\"Loading and splitting into chunks: {pdf_file_name}\")\n",
    "\n",
    "    loader = PyPDFLoader(pdf_file_name)\n",
    "    data = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=64)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_df(df):\n",
    "    \"\"\"\n",
    "    Expands each row in the DataFrame by splitting PDF documents into chunks.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing 'pdf_file_name', 'arxiv_id', 'title', 'summary', \n",
    "                           'authors', and 'url' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame where each row represents a chunk of the original document, \n",
    "                      with additional metadata such as chunk identifiers and relationships to \n",
    "                      adjacent chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    expanded_rows = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            chunks = load_and_chunk_pdf(row[\"pdf_file_name\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {row['pdf_file_name']}: {e}\")\n",
    "            continue\n",
    "\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            prechunk_id = i-1 if i > 0 else \"\"\n",
    "            postchunk_id = i+1 if i < len(chunks)-1 else \"\"\n",
    "\n",
    "            expanded_rows.append({\n",
    "                \"id\": f\"{row['arxiv_id']}#{i}\",\n",
    "                \"title\": row[\"title\"],\n",
    "                \"summary\": row[\"summary\"],\n",
    "                \"authors\": row[\"authors\"],\n",
    "                \"arxiv_id\": row[\"arxiv_id\"],\n",
    "                \"url\": row[\"url\"],\n",
    "                \"chunk\": chunk.page_content,\n",
    "                \"prechunk_id\": \"\" if i == 0 else f\"{row['arxiv_id']}#{prechunk_id}\",\n",
    "                \"postchunk_id\": \"\" if i == len(chunks)-1 else f\"{row['arxiv_id']}#{postchunk_id}\"\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(expanded_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and splitting into chunks: files/9308101v1.pdf\n",
      "Loading and splitting into chunks: files/9308102v1.pdf\n",
      "Loading and splitting into chunks: files/9309101v1.pdf\n",
      "Loading and splitting into chunks: files/9311101v1.pdf\n",
      "Loading and splitting into chunks: files/9311102v1.pdf\n",
      "Loading and splitting into chunks: files/9312101v1.pdf\n",
      "Loading and splitting into chunks: files/9401101v1.pdf\n",
      "Loading and splitting into chunks: files/9402101v1.pdf\n",
      "Loading and splitting into chunks: files/9402102v1.pdf\n",
      "Loading and splitting into chunks: files/9402103v1.pdf\n",
      "Loading and splitting into chunks: files/9403101v1.pdf\n",
      "Loading and splitting into chunks: files/9406101v1.pdf\n",
      "Loading and splitting into chunks: files/9406102v1.pdf\n",
      "Loading and splitting into chunks: files/9408101v1.pdf\n",
      "Loading and splitting into chunks: files/9408102v1.pdf\n",
      "Loading and splitting into chunks: files/9408103v1.pdf\n",
      "Loading and splitting into chunks: files/9409101v1.pdf\n",
      "Loading and splitting into chunks: files/9412101v1.pdf\n",
      "Loading and splitting into chunks: files/9412102v1.pdf\n",
      "Loading and splitting into chunks: files/9412103v1.pdf\n"
     ]
    }
   ],
   "source": [
    "expanded_df = expand_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from semantic_router.encoders import OpenAIEncoder\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass(\"OpenAI API key: \")\n",
    "\n",
    "encoder = OpenAIEncoder(name=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = len(encoder(\"hello hallo hola salut\")[0])\n",
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\") or getpass(\"Pinecone API key: \")\n",
    "\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "spec = ServerlessSpec(\n",
    "    cloud=\"aws\",\n",
    "    region=\"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'cosine',\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "index_name = \"langgraph-research-agent\"\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=dims,\n",
    "        metric=\"cosine\",\n",
    "        spec=spec\n",
    "    )\n",
    "\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expanded_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mexpanded_df\u001b[49m.iloc[:\u001b[32m5\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'expanded_df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb3109a4ca64e0495e43482652ea34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "data = expanded_df\n",
    "batch_size = 64\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i + batch_size)\n",
    "    batch = data[i:i_end].to_dict(orient=\"records\")\n",
    "\n",
    "    metadata = [{\n",
    "        'arxiv_id': r[\"arxiv_id\"],\n",
    "        'title': r[\"title\"],\n",
    "        'summary': r['chunk']\n",
    "    } for r in batch]\n",
    "\n",
    "    ids = [r[\"id\"] for r in batch]\n",
    "\n",
    "    chunks = [r[\"chunk\"] for r in batch]\n",
    "    \n",
    "    embeds = encoder(chunks)\n",
    "\n",
    "    index.upsert(vectors=zip(ids, embeds, metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'cosine',\n",
       " 'namespaces': {'': {'vector_count': 4608}},\n",
       " 'total_vector_count': 4608,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html lang=\"en\">\\n\\n<head>  <title>[1706.03762] Attention Is All You Need</title>\\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n  <link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/static/browse/0.3.4/images/icons/apple-touch-icon.png\">\\n  <link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"/static/browse/0.3.4/images/icons/favicon-32x32.png\">\\n  <link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"/static/browse/0.3.4/images/icons/favicon-16x16.png\">\\n  <link rel=\"manifest\" href=\"/static/browse/0.3.4/images/icons/site.webmanifest\">\\n  <link rel=\"mask-icon\" href=\"/static/browse/0.3.4/images/icons/safari-pinned-tab.svg\" color=\"#5bbad5\">\\n  <meta name=\"msapplication-TileColor\" content=\"#da532c\">\\n  <meta name=\"theme-color\" content=\"#ffffff\">\\n  <link rel=\"stylesheet\" type=\"text/css\" media=\"screen\" href=\"/static/browse/0.3.4/css/arXiv.css?v=20241206\" />\\n  <link rel=\"stylesheet\" type=\"text/css\" media=\"print\" href=\"/static/browse/0.3.4/css/arXiv-print.css?v=20200611\" />\\n  <link rel=\"stylesheet\" type=\"text/css\" media=\"screen\" href=\"/static/browse/0.3.4/css/browse_search.css\" />\\n  <script language=\"javascript\" src=\"/static/browse/0.3.4/js/accordion.js\" /></script>\\n  <link rel=\"canonical\" href=\"https://arxiv.org/abs/1706.03762\"/>\\n  <meta name=\"description\" content=\"Abstract page for arXiv paper 1706.03762: Attention Is All You Need\"><meta property=\"og:type\" content=\"website\" />\\n<meta property=\"og:site_name\" content=\"arXiv.org\" />\\n<meta property=\"og:title\" content=\"Attention Is All You Need\" />\\n<meta property=\"og:url\" content=\"https://arxiv.org/abs/1706.03762v7\" />\\n<meta property=\"og:image\" content=\"/static/browse/0.3.4/images/arxiv-logo-fb.png\" />\\n<meta property=\"og:image:secure_url\" content=\"/static/browse/0.3.4/images/arxiv-logo-fb.png\" />\\n<meta property=\"og:image:width\" content=\"1200\" />\\n<meta property=\"og:image:height\" content=\"700\" />\\n<meta property=\"og:image:alt\" content=\"arXiv logo\"/>\\n<meta property=\"og:description\" content=\"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\"/>\\n<meta name=\"twitter:site\" content=\"@arxiv\"/>\\n<meta name=\"twitter:card\" content=\"summary\"/>\\n<meta name=\"twitter:title\" content=\"Attention Is All You Need\"/>\\n<meta name=\"twitter:description\" content=\"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder...\"/>\\n<meta name=\"twitter:image\" content=\"https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png\"/>\\n<meta name=\"twitter:image:alt\" content=\"arXiv logo\"/>\\n  <link rel=\"stylesheet\" media=\"screen\" type=\"text/css\" href=\"/static/browse/0.3.4/css/tooltip.css\"/><link rel=\"stylesheet\" media=\"screen\" type=\"text/css\" href=\"https://static.arxiv.org/js/bibex-dev/bibex.css?20200709\"/>  <script src=\"/static/browse/0.3.4/js/mathjaxToggle.min.js\" type=\"text/javascript\"></script>  <script src=\"//code.jquery.com/jquery-latest.min.js\" type=\"text/javascript\"></script>\\n  <script src=\"//cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js\" type=\"text/javascript\"></script>\\n  <script src=\"//cdn.jsdelivr.net/npm/dompurify@2.3.5/dist/purify.min.js\"></script>\\n  <script src=\"/static/browse/0.3.4/js/toggle-labs.js?20241022\" type=\"text/javascript\"></script>\\n  <script src=\"/static/browse/0.3.4/js/cite.js\" type=\"text/javascript\"></script><meta name=\"citation_title\" content=\"Attention Is All You Need\" /><meta name=\"citation_author\" content=\"Vaswani, Ashish\" /><meta name=\"citation_author\" content=\"Shazeer, Noam\" /><meta name=\"citation_author\" content=\"Parmar, Niki\" /><meta name=\"citation_author\" content=\"Uszkoreit, Jakob\" /><meta name=\"citation_author\" content=\"Jones, Llion\" /><meta name=\"citation_author\" content=\"Gomez, Aidan N.\" /><meta name=\"citation_author\" content=\"Kaiser, Lukasz\" /><meta name=\"citation_author\" content=\"Polosukhin, Illia\" /><meta name=\"citation_date\" content=\"2017/06/12\" /><meta name=\"citation_online_date\" content=\"2023/08/02\" /><meta name=\"citation_pdf_url\" content=\"http://arxiv.org/pdf/1706.03762\" /><meta name=\"citation_arxiv_id\" content=\"1706.03762\" /><meta name=\"citation_abstract\" content=\"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\" />\\n</head>\\n\\n<body  class=\"with-cu-identity\">\\n  \\n  <div class=\"flex-wrap-footer\">\\n    <header>\\n      <a href=\"#content\" class=\"is-sr-only\">Skip to main content</a>\\n      <!-- start desktop header -->\\n      <div class=\"columns is-vcentered is-hidden-mobile\" id=\"cu-identity\">\\n        <div class=\"column\" id=\"cu-logo\">\\n          <a href=\"https://www.cornell.edu/\"><img src=\"/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg\" alt=\"Cornell University\" /></a>\\n        </div>\\n\\n\\n        <!-- /from April 7 at 1:00 AM to May 29 at 21:40 --><!-- /from May 2 at 1:00 AM to May 5 at 9:45 AM --><div class=\"column\" id=\"support-ack\">\\n          <span id=\"support-ack-url\">We gratefully acknowledge support from the Simons Foundation, <a href=\"https://info.arxiv.org/about/ourmembers.html\">member institutions</a>, and all contributors.</span>\\n          <a href=\"https://info.arxiv.org/about/donate.html\" class=\"btn-header-donate\">Donate</a>\\n        </div>\\n      </div>\\n\\n      <div id=\"header\" class=\"is-hidden-mobile\">\\n<a aria-hidden=\"true\" tabindex=\"-1\" href=\"/IgnoreMe\"></a>\\n  <div class=\"header-breadcrumbs is-hidden-mobile\">\\n    <a href=\"/\"><img src=\"/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg\" alt=\"arxiv logo\" style=\"height:40px;\"/></a> <span>&gt;</span> <a href=\"/list/cs/recent\">cs</a> <span>&gt;</span> arXiv:1706.03762\\n  </div>\\n          <div class=\"search-block level-right\">\\n    <form class=\"level-item mini-search\" method=\"GET\" action=\"https://arxiv.org/search\">\\n      <div class=\"field has-addons\">\\n        <div class=\"control\">\\n          <input class=\"input is-small\" type=\"text\" name=\"query\" placeholder=\"Search...\" aria-label=\"Search term or terms\" />\\n          <p class=\"help\"><a href=\"https://info.arxiv.org/help\">Help</a> | <a href=\"https://arxiv.org/search/advanced\">Advanced Search</a></p>\\n        </div>\\n        <div class=\"control\">\\n          <div class=\"select is-small\">\\n            <select name=\"searchtype\" aria-label=\"Field to search\">\\n              <option value=\"all\" selected=\"selected\">All fields</option>\\n              <option value=\"title\">Title</option>\\n              <option value=\"author\">Author</option>\\n              <option value=\"abstract\">Abstract</option>\\n              <option value=\"comments\">Comments</option>\\n              <option value=\"journal_ref\">Journal reference</option>\\n              <option value=\"acm_class\">ACM classification</option>\\n              <option value=\"msc_class\">MSC classification</option>\\n              <option value=\"report_num\">Report number</option>\\n              <option value=\"paper_id\">arXiv identifier</option>\\n              <option value=\"doi\">DOI</option>\\n              <option value=\"orcid\">ORCID</option>\\n              <option value=\"author_id\">arXiv author ID</option>\\n              <option value=\"help\">Help pages</option>\\n              <option value=\"full_text\">Full text</option>\\n            </select>\\n          </div>\\n        </div>\\n        <input type=\"hidden\" name=\"source\" value=\"header\">\\n        <button class=\"button is-small is-cul-darker\">Search</button>\\n      </div>\\n    </form>\\n  </div>\\n     </div><!-- /end desktop header -->\\n\\n      <div class=\"mobile-header\">\\n        <div class=\"columns is-mobile\">\\n          <div class=\"column logo-arxiv\"><a href=\"https://arxiv.org/\"><img src=\"/static/browse/0.3.4/images/arxiv-logomark-small-white.svg\" alt=\"arXiv logo\" style=\"height:60px;\" /></a></div>\\n          <div class=\"column logo-cornell\"><a href=\"https://www.cornell.edu/\">\\n            <picture>\\n              <source media=\"(min-width: 501px)\"\\n                srcset=\"/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg  400w\"\\n                sizes=\"400w\" />\\n              <source srcset=\"/static/browse/0.3.4/images/icons/cu/cornell_seal_simple_black.svg 2x\" />\\n              <img src=\"/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg\" alt=\"Cornell University Logo\" />\\n            </picture>\\n          </a></div>\\n          <div class=\"column nav\" id=\"toggle-container\" role=\"menubar\">\\n            <button class=\"toggle-control\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\" class=\"icon filter-white\"><title>open search</title><path d=\"M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z\"/></svg></button>\\n            <div class=\"mobile-toggle-block toggle-target\">\\n              <form class=\"mobile-search-form\" method=\"GET\" action=\"https://arxiv.org/search\">\\n                <div class=\"field has-addons\">\\n                  <input class=\"input\" type=\"text\" name=\"query\" placeholder=\"Search...\" aria-label=\"Search term or terms\" />\\n                  <input type=\"hidden\" name=\"source\" value=\"header\">\\n                  <input type=\"hidden\" name=\"searchtype\" value=\"all\">\\n                  <button class=\"button\">GO</button>\\n                </div>\\n              </form>\\n            </div>\\n\\n            <button class=\"toggle-control\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 448 512\" class=\"icon filter-white\" role=\"menu\"><title>open navigation menu</title><path d=\"M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z\"/ ></svg></button>\\n            <div class=\"mobile-toggle-block toggle-target\">\\n              <nav class=\"mobile-menu\" aria-labelledby=\"mobilemenulabel\">\\n                <h2 id=\"mobilemenulabel\">quick links</h2>\\n                <ul>\\n                    <li><a href=\"https://arxiv.org/login\">Login</a></li>\\n                    <li><a href=\"https://info.arxiv.org/help\">Help Pages</a></li>\\n                    <li><a href=\"https://info.arxiv.org/about\">About</a></li>\\n                </ul>\\n              </nav>\\n            </div>\\n          </div>\\n        </div>\\n      </div><!-- /end mobile-header -->\\n    </header>\\n\\n    <main>\\n      <div id=\"content\">\\n<!--\\nrdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\\n         xmlns:dc=\"http://purl.org/dc/elements/1.1/\"\\n         xmlns:trackback=\"http://madskills.com/public/xml/rss/module/trackback/\">\\n    <rdf:Description\\n        rdf:about=\"/abs/1706.03762\"\\n        dc:identifier=\"/abs/1706.03762\"\\n        dc:title=\"Attention Is All You Need\"\\n        trackback:ping=\"/trackback/1706.03762\" />\\n    </rdf:RDF>\\n--><div id=\"abs-outer\">\\n\\n  <div class=\"leftcolumn\">\\n    <div class=\"subheader\">\\n      <h1>Computer Science > Computation and Language</h1>\\n    </div>\\n\\n    <div class=\"header-breadcrumbs-mobile\">\\n      <strong>arXiv:1706.03762</strong> (cs)\\n    </div>\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"/static/base/1.0.1/css/abs.css\">\\n<div id=\"content-inner\">\\n  <div id=\"abs\">\\n    <div class=\"dateline\">\\n  [Submitted on 12 Jun 2017 (<a href=\"https://arxiv.org/abs/1706.03762v1\">v1</a>), last revised 2 Aug 2023 (this version, v7)]</div>\\n    <h1 class=\"title mathjax\"><span class=\"descriptor\">Title:</span>Attention Is All You Need</h1>\\n    <div class=\"authors\"><span class=\"descriptor\">Authors:</span><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Vaswani,+A\" rel=\"nofollow\">Ashish Vaswani</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shazeer,+N\" rel=\"nofollow\">Noam Shazeer</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Parmar,+N\" rel=\"nofollow\">Niki Parmar</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Uszkoreit,+J\" rel=\"nofollow\">Jakob Uszkoreit</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jones,+L\" rel=\"nofollow\">Llion Jones</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gomez,+A+N\" rel=\"nofollow\">Aidan N. Gomez</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kaiser,+L\" rel=\"nofollow\">Lukasz Kaiser</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Polosukhin,+I\" rel=\"nofollow\">Illia Polosukhin</a></div>            <div id=\"download-button-info\" hidden>View a PDF of the paper titled Attention Is All You Need, by Ashish Vaswani and 7 other authors</div>\\n    <a class=\"mobile-submission-download\" href=\"/pdf/1706.03762\">View PDF</a>\\n    <a class=\"mobile-submission-download\" href=\"https://arxiv.org/html/1706.03762v7\">HTML (experimental)</a>\\n\\n\\n\\n    <blockquote class=\"abstract mathjax\">\\n            <span class=\"descriptor\">Abstract:</span>The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\\n    </blockquote>\\n\\n    <!--CONTEXT-->\\n    <div class=\"metatable\">\\n      <table summary=\"Additional metadata\">        <tr>\\n          <td class=\"tablecell label\">Comments:</td>\\n          <td class=\"tablecell comments mathjax\">15 pages, 5 figures</td>\\n        </tr>\\n<tr>\\n          <td class=\"tablecell label\">Subjects:</td>\\n          <td class=\"tablecell subjects\">\\n            <span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)</td>\\n        </tr><tr>\\n          <td class=\"tablecell label\">Cite as:</td>\\n          <td class=\"tablecell arxivid\"><span class=\"arxivid\"><a href=\"https://arxiv.org/abs/1706.03762\">arXiv:1706.03762</a> [cs.CL]</span></td>\\n        </tr>\\n        <tr>\\n          <td class=\"tablecell label\">&nbsp;</td>\\n          <td class=\"tablecell arxividv\">(or <span class=\"arxivid\">\\n              <a href=\"https://arxiv.org/abs/1706.03762v7\">arXiv:1706.03762v7</a> [cs.CL]</span> for this version)\\n          </td>\\n        </tr>\\n        <tr>\\n          <td class=\"tablecell label\">&nbsp;</td>\\n          <td class=\"tablecell arxivdoi\">              <a href=\"https://doi.org/10.48550/arXiv.1706.03762\"  id=\"arxiv-doi-link\">https://doi.org/10.48550/arXiv.1706.03762</a><div class=\"button-and-tooltip\">\\n              <button class=\"more-info\" aria-describedby=\"more-info-desc-1\">\\n                <svg height=\"15\" role=\"presentation\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"><path fill=\"currentColor\" d=\"M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z\" class=\"\"></path></svg>\\n                <span class=\"visually-hidden\">Focus to learn more</span>\\n              </button>\\n              <!-- tooltip description -->\\n              <div role=\"tooltip\" id=\"more-info-desc-1\">\\n                <span class=\"left-corner\"></span>                  arXiv-issued DOI via DataCite</div>\\n            </div>\\n          </td>\\n        </tr></table>\\n    </div>\\n  </div>\\n</div>\\n    <div class=\"submission-history\">\\n      <h2>Submission history</h2> From: Llion Jones [<a href=\"/show-email/f53b7360/1706.03762\" rel=\"nofollow\">view email</a>]      <br/>            <strong><a href=\"/abs/1706.03762v1\" rel=\"nofollow\">[v1]</a></strong>\\n        Mon, 12 Jun 2017 17:57:34 UTC (1,102 KB)<br/>\\n            <strong><a href=\"/abs/1706.03762v2\" rel=\"nofollow\">[v2]</a></strong>\\n        Mon, 19 Jun 2017 16:49:45 UTC (1,125 KB)<br/>\\n            <strong><a href=\"/abs/1706.03762v3\" rel=\"nofollow\">[v3]</a></strong>\\n        Tue, 20 Jun 2017 05:20:02 UTC (1,125 KB)<br/>\\n            <strong><a href=\"/abs/1706.03762v4\" rel=\"nofollow\">[v4]</a></strong>\\n        Fri, 30 Jun 2017 17:29:30 UTC (1,124 KB)<br/>\\n            <strong><a href=\"/abs/1706.03762v5\" rel=\"nofollow\">[v5]</a></strong>\\n        Wed, 6 Dec 2017 03:30:32 UTC (1,124 KB)<br/>\\n            <strong><a href=\"/abs/1706.03762v6\" rel=\"nofollow\">[v6]</a></strong>\\n        Mon, 24 Jul 2023 00:48:54 UTC (1,124 KB)<br/>\\n    <strong>[v7]</strong>\\n        Wed, 2 Aug 2023 00:41:18 UTC (1,124 KB)<br/>\\n</div>\\n  </div>\\n  <!--end leftcolumn-->\\n<div class=\"extra-services\">    <div class=\"full-text\">\\n      <a name=\"other\"></a>\\n      <span class=\"descriptor\">Full-text links:</span>\\n      <h2>Access Paper:</h2>\\n      <ul>\\n  <div id=\"download-button-info\" hidden>\\nView a PDF of the paper titled Attention Is All You Need, by Ashish Vaswani and 7 other authors</div><li><a href=\"/pdf/1706.03762\" aria-describedby=\"download-button-info\" accesskey=\"f\" class=\"abs-button download-pdf\">View PDF</a></li><li><a href=\"https://arxiv.org/html/1706.03762v7\" class=\"abs-button\" id=\"latexml-download-link\">HTML (experimental)</a></li><li><a href=\"/src/1706.03762\" class=\"abs-button download-eprint\">TeX Source</a></li><li><a href=\"/format/1706.03762\" class=\"abs-button download-format\">Other Formats</a></li></ul>\\n      <div class=\"abs-license\"><a href=\"http://arxiv.org/licenses/nonexclusive-distrib/1.0/\" title=\"Rights to this article\">view license</a></div>\\n    </div>\\n    <!--end full-text-->    <div class=\"browse\">\\n    Current browse context: <div class=\"current\">cs.CL</div>\\n\\n  <div class=\"prevnext\">\\n<span class=\"arrow\">\\n      <a class=\"abs-button prev-url\" href=\"/prevnext?id=1706.03762&amp;function=prev&amp;context=cs.CL\"\\n         accesskey=\"p\" title=\"previous in cs.CL (accesskey p)\" rel=\"nofollow\">&lt;&nbsp;prev</a>\\n    </span>\\n    <span class=\"is-hidden-mobile\">&nbsp; | &nbsp;</span>    <span class=\"arrow\">\\n      <a class=\"abs-button next-url\" href=\"/prevnext?id=1706.03762&amp;function=next&amp;context=cs.CL\" accesskey=\"n\"\\n         title=\"next in cs.CL (accesskey n)\"  rel=\"nofollow\">next&nbsp;&gt;</a>\\n    </span><br/>\\n  </div><div class=\"list\">\\n    <a class=\"abs-button abs-button-grey abs-button-small context-new\" href=\"/list/cs.CL/new\"  rel=\"nofollow\">new</a>\\n    <span class=\"is-hidden-mobile\"> | </span>\\n    <a class=\"abs-button abs-button-grey abs-button-small context-recent\" href=\"/list/cs.CL/recent\" rel=\"nofollow\">recent</a>\\n    <span class=\"is-hidden-mobile\"> | </span><a class=\"abs-button abs-button-grey abs-button-small context-id\" href=\"/list/cs.CL/2017-06\" rel=\"nofollow\">2017-06</a>\\n  </div><div class=\"abs-switch-cat\">\\n    Change to browse by:\\n    <div class=\"switch context-change\">\\n        <a href=\"/abs/1706.03762?context=cs\" rel=\"nofollow\">cs</a><br class=\"is-hidden-mobile\">\\n        <a class=\"subclass\" href=\"/abs/1706.03762?context=cs.LG\" rel=\"nofollow\">cs.LG</a><br class=\"is-hidden-mobile\">\\n    </div>\\n  </div>\\n\\n    </div>\\n      <div class=\"extra-ref-cite\">\\n        <h3>References &amp; Citations</h3>\\n        <ul>\\n          <li><a  class=\"abs-button abs-button-small cite-ads\" href=\"https://ui.adsabs.harvard.edu/abs/arXiv:1706.03762\">NASA ADS</a></li><li><a  class=\"abs-button abs-button-small cite-google-scholar\" href=\"https://scholar.google.com/scholar_lookup?arxiv_id=1706.03762\" target=\"_blank\" rel=\"noopener\">Google Scholar</a></li>\\n          <li><a  class=\"abs-button abs-button-small cite-semantic-scholar\" href=\"https://api.semanticscholar.org/arXiv:1706.03762\" target=\"_blank\" rel=\"noopener\">Semantic Scholar</a></li>\\n        </ul>\\n        <div style=\"clear:both;\"></div>\\n      </div>\\n\\n    <div class=\"extra-general\">\\n        <div class=\"what-is-this\">\\n            <h3><a  class=\"abs-button abs-button-grey abs-button-small trackback-link\" href=\"/tb/1706.03762\"> 123 blog links</a></h3> (<a href=\"https://info.arxiv.org/help/trackback.html\" class=\"trackback-help\">what is this?</a>)\\n        </div>\\n    </div>\\n<div class=\"dblp\">\\n    <h3><a href=\"https://dblp.uni-trier.de\">DBLP</a> - CS Bibliography</h3>\\n    <div class=\"list\">\\n      <a href=\"https://dblp.uni-trier.de/db/journals/corr/corr1706.html#VaswaniSPUJGKP17\" title=\"listing on DBLP\">listing</a> | <a href=\"https://dblp.uni-trier.de/rec/bibtex/journals/corr/VaswaniSPUJGKP17\" title=\"DBLP bibtex record\">bibtex</a>    </div>\\n    <div class=\"list\">\\n<a href=\"https://dblp.uni-trier.de/search/author?author=Ashish%20Vaswani\" title=\"DBLP author search\">Ashish Vaswani</a><br/><a href=\"https://dblp.uni-trier.de/search/author?author=Noam%20Shazeer\" title=\"DBLP author search\">Noam Shazeer</a><br/><a href=\"https://dblp.uni-trier.de/search/author?author=Niki%20Parmar\" title=\"DBLP author search\">Niki Parmar</a><br/><a href=\"https://dblp.uni-trier.de/search/author?author=Jakob%20Uszkoreit\" title=\"DBLP author search\">Jakob Uszkoreit</a><br/><a href=\"https://dblp.uni-trier.de/search/author?author=Llion%20Jones\" title=\"DBLP author search\">Llion Jones</a>      <div class=\"list\">&hellip;</div>\\n    </div>\\n  </div><div class=\\'extra-ref-cite\\'>\\n    <a id=\\'bib-cite-css\\' hidden=\\'true\\' href=\\'/static/browse/0.3.4/css/cite.css\\'>a</a>\\n\\n    <span id=\\'bib-cite-trigger\\' class=\"bib-cite-button abs-button\">export BibTeX citation</span>\\n    <span id=\\'bib-cite-loading\\' hidden=\\'true\\'>Loading...</span>\\n</div>\\n\\n<div id=\\'bib-cite-modal\\' class=\\'bib-modal\\' hidden=\\'true\\'>\\n    <div class=\\'bib-modal-content\\'>\\n        <div class=\\'bib-modal-title\\'>\\n            <h2>BibTeX formatted citation</h2>\\n            <span class=\\'bib-modal-close\\' >&times;</span>\\n        </div>\\n        <div>\\n            <textarea id=\\'bib-cite-target\\' class=\"bib-citation-content\" aria-label=\"loading the citation\">loading...</textarea>\\n        </div>\\n        <div>\\n            <span>Data provided by: </span>\\n            <a id=\\'bib-cite-source-api\\'></a>\\n        </div>\\n    </div>\\n</div><div class=\"bookmarks\">\\n  <div><h3>Bookmark</h3></div><a class=\"abs-button abs-button-grey abs-button-small\" href=\"http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/1706.03762&amp;description=Attention Is All You Need\"\\n     title=\"Bookmark on BibSonomy\">\\n    <img src=\"/static/browse/0.3.4/images/icons/social/bibsonomy.png\"\\n         alt=\"BibSonomy logo\"/>\\n  </a>\\n  <a class=\"abs-button abs-button-grey abs-button-small\" href=\"https://reddit.com/submit?url=https://arxiv.org/abs/1706.03762&amp;title=Attention Is All You Need\"\\n     title=\"Bookmark on Reddit\">\\n    <img src=\"/static/browse/0.3.4/images/icons/social/reddit.png\"\\n         alt=\"Reddit logo\"/>\\n  </a>\\n</div>  </div>\\n  <!--end extra-services-->\\n<!-- LABS AREA -->\\n<div id=\"labstabs\">\\n  <div class=\"labstabs\"><input type=\"radio\" name=\"tabs\" id=\"tabone\"checked=\"checked\">\\n    <label for=\"tabone\">Bibliographic Tools</label>\\n    <div class=\"tab labs-display-bib\">\\n      <h1>Bibliographic and Citation Tools</h1>\\n      <div class=\"toggle\">\\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input id=\"bibex-toggle\" type=\"checkbox\" class=\"lab-toggle\"\\n                     data-script-url=\"/static/browse/0.3.4/bibex/bibex.js?20241202\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">Bibliographic Explorer Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-bibex\">Bibliographic Explorer</span> <em>(<a href=\"https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer\">What is the Explorer?</a>)</em>\\n          </div>\\n        </div>\\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input\\n                id=\"connectedpapers-toggle\"\\n                type=\"checkbox\"\\n                class=\"lab-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/connectedpapers.js\"\\n                aria-labelledby=\"label-for-connected-papers\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">Connected Papers Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-connected-papers\">Connected Papers</span> <em>(<a href=\"https://www.connectedpapers.com/about\" target=\"_blank\">What is Connected Papers?</a>)</em>\\n          </div>\\n        </div><div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input\\n                id=\"litmaps-toggle\"\\n                type=\"checkbox\"\\n                class=\"lab-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/litmaps.js?20210617\"\\n                aria-labelledby=\"label-for-litmaps\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">Litmaps Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-litmaps\">Litmaps</span> <em>(<a href=\"https://www.litmaps.co/\" target=\"_blank\">What is Litmaps?</a>)</em>\\n          </div>\\n        </div>\\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input\\n                id=\"scite-toggle\"\\n                type=\"checkbox\"\\n                class=\"lab-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/scite.js?20210617\"\\n                aria-labelledby=\"label-for-scite\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">scite.ai Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-scite\">scite Smart Citations</span> <em>(<a href=\"https://www.scite.ai/\" target=\"_blank\">What are Smart Citations?</a>)</em>\\n          </div>\\n        </div>\\n      </div>\\n        <div class=\"labs-content-placeholder labs-display\" style=\"display: none;\"></div>\\n        <div style=\"min-height: 15px\" id=\"connectedpapers-output\"></div>\\n        <div style=\"min-height: 15px\" id=\"litmaps-open-in\"></div>\\n        <div style=\"min-height: 15px\" id=\"scite-open-in\"></div>\\n    </div>\\n\\n\\n    <input type=\"radio\" name=\"tabs\" id=\"tabtwo\">\\n    <label for=\"tabtwo\">Code, Data, Media</label>\\n    <div class=\"tab\">\\n      <h1>Code, Data and Media Associated with this Article</h1>\\n      <div class=\"toggle\">\\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input\\n                id=\"alphaxiv-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/alphaxiv.js\"\\n                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-alphaxiv\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">alphaXiv Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-alphaxiv\">alphaXiv</span> <em>(<a href=\"https://alphaxiv.org/\" target=\"_blank\">What is alphaXiv?</a>)</em>\\n          </div>\\n        </div>\\n\\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input        \\n                id=\"catalyzex-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/catalyzex.js\"\\n                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-cx\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">Links to Code Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-cx\">CatalyzeX Code Finder for Papers</span> <em>(<a href=\"https://www.catalyzex.com\" target=\"_blank\">What is CatalyzeX?</a>)</em>\\n          </div>\\n        </div>\\n\\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input\\n                id=\"dagshub-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/dagshub.js\"\\n                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-dagshub\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">DagsHub Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-dagshub\">DagsHub</span> <em>(<a href=\"https://dagshub.com/\" target=\"_blank\">What is DagsHub?</a>)</em>\\n          </div>\\n        </div>\\n  \\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input\\n                id=\"gotitpub-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/gotitpub.js\"\\n                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-gotitpub\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">GotitPub Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-gotitpub\">Gotit.pub</span> <em>(<a href=\"http://gotit.pub/faq\" target=\"_blank\">What is GotitPub?</a>)</em>\\n          </div>\\n        </div>\\n\\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input\\n                id=\"huggingface-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/huggingface.js\"\\n                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-huggingface\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">Huggingface Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-huggingface\">Hugging Face</span> <em>(<a href=\"https://huggingface.co/huggingface\" target=\"_blank\">What is Huggingface?</a>)</em>\\n          </div>\\n        </div>\\n\\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input\\n                id=\"paperwithcode-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/paperswithcode.js\"\\n                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-pwc\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">Links to Code Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-pwc\">Papers with Code</span> <em>(<a href=\"https://paperswithcode.com/\" target=\"_blank\">What is Papers with Code?</a>)</em>\\n          </div>\\n        </div>\\n\\n\\n        <div class=\"columns is-mobile lab-row\">\\n          <div class=\"column lab-switch\">\\n            <label class=\"switch\">\\n              <input\\n                id=\"sciencecast-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/sciencecast.js\"\\n                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-sciencecast\">\\n              <span class=\"slider\"></span>\\n              <span class=\"is-sr-only\">ScienceCast Toggle</span>\\n            </label>\\n          </div>\\n          <div class=\"column lab-name\">\\n            <span id=\"label-for-sciencecast\">ScienceCast</span> <em>(<a href=\"https://sciencecast.org/welcome\" target=\"_blank\">What is ScienceCast?</a>)</em>\\n          </div>\\n        </div>\\n      </div>\\n\\n      <div id=\"alphaxiv-output\" style=\"display:none\"></div>\\n      <div id=\"catalyzex-output\" style=\"display:none\"></div>\\n      <div id=\"dagshub-output\" style=\"display:none\"></div>\\n      <div id=\"gotitpub-output\" style=\"display:none\"></div>\\n      <div id=\"pwc-output\" style=\"display:none\"></div>\\n      <div id=\"pwc-data-output\" style=\"display:none\"></div>\\n      <div id=\"sciencecast-output\" style=\"display:none\"></div>\\n      <div id=\"huggingface-output\" style=\"display:none\"></div>\\n    </div>\\n\\n\\n      <input type=\"radio\" name=\"tabs\" id=\"labstabs-demos-input\">\\n      <label for=\"labstabs-demos-input\" id=\"labstabs-demos-label\">Demos</label>\\n      <div class=\"tab\">\\n        <h1>Demos</h1>\\n        <div class=\"toggle\">\\n          <div class=\"columns is-mobile lab-row\">\\n            <div class=\"column lab-switch\">\\n              <label class=\"switch\">\\n                <input\\n                  id=\"replicate-toggle\"\\n                  data-script-url=\"/static/browse/0.3.4/js/replicate.js\"\\n                  type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-replicate\">\\n                <span class=\"slider\"></span>\\n                <span class=\"is-sr-only\">Replicate Toggle</span>\\n              </label>\\n            </div>\\n            <div class=\"column lab-name\">\\n              <span id=\"label-for-replicate\">Replicate</span> <em>(<a href=\"https://replicate.com/docs/arxiv/about\" target=\"_blank\">What is Replicate?</a>)</em>\\n            </div>\\n          </div>\\n          <div class=\"columns is-mobile lab-row\">\\n            <div class=\"column lab-switch\">\\n              <label class=\"switch\">\\n                <input\\n                  id=\"spaces-toggle\"\\n                  data-script-url=\"/static/browse/0.3.4/js/spaces.js\"\\n                  type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-spaces\">\\n                <span class=\"slider\"></span>\\n                <span class=\"is-sr-only\">Spaces Toggle</span>\\n              </label>\\n            </div>\\n            <div class=\"column lab-name\">\\n              <span id=\"label-for-spaces\">Hugging Face Spaces</span> <em>(<a href=\"https://huggingface.co/docs/hub/spaces\" target=\"_blank\">What is Spaces?</a>)</em>\\n            </div>\\n          </div>\\n          <div class=\"columns is-mobile lab-row\">\\n            <div class=\"column lab-switch\">\\n              <label class=\"switch\">\\n                <input\\n                  id=\"txyz-toggle\"\\n                  data-script-url=\"/static/browse/0.3.4/js/txyz.js\"\\n                  type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-txyz\">\\n                <span class=\"slider\"></span>\\n                <span class=\"is-sr-only\">Spaces Toggle</span>\\n              </label>\\n            </div>\\n            <div class=\"column lab-name\">\\n              <span id=\"label-for-txyz\">TXYZ.AI</span> <em>(<a href=\"https://txyz.ai\" target=\"_blank\">What is TXYZ.AI?</a>)</em>\\n            </div>\\n          </div>\\n        </div>\\n        <div id=\"replicate-output\"></div>\\n        <div id=\"spaces-output\"></div>\\n        <div id=\"txyz-output\"></div>\\n      </div>\\n      <input type=\"radio\" name=\"tabs\" id=\"tabfour\">\\n      <label for=\"tabfour\">Related Papers</label>\\n      <div class=\"tab\">\\n        <h1>Recommenders and Search Tools</h1>\\n        <div class=\"toggle\">\\n          <div class=\"columns is-mobile lab-row\">\\n            <div class=\"column lab-switch\">\\n              <label class=\"switch\">\\n                <input id=\"influenceflower-toggle\"\\n                data-script-url=\"/static/browse/0.3.4/js/influenceflower.js\"\\n                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-influenceflower\">\\n                <span class=\"slider\"></span>\\n                <span class=\"is-sr-only\">Link to Influence Flower</span>\\n              </label>\\n            </div>\\n            <div class=\"column lab-name\">\\n              <span id=\"label-for-influenceflower\">Influence Flower</span> <em>(<a href=\"https://influencemap.cmlab.dev/\" target=\"_blank\">What are Influence Flowers?</a>)</em>\\n            </div>\\n          </div>\\n          <div class=\"columns is-mobile lab-row\">\\n            <div class=\"column lab-switch\">\\n              <label class=\"switch\">\\n                <input id=\"core-recommender-toggle\" type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-core\">\\n                <span class=\"slider\"></span>\\n                <span class=\"is-sr-only\">Core recommender toggle</span>\\n              </label>\\n            </div>\\n            <div class=\"column lab-name\">\\n              <span id=\"label-for-core\">CORE Recommender</span> <em>(<a href=\"https://core.ac.uk/services/recommender\">What is CORE?</a>)</em>\\n            </div>\\n          </div></div>\\n        <div id=\"influenceflower-output\"></div>\\n        <div id=\"influenceflower-output-graph\" style=\"display:none\">\\n          <ul class=\"flower-tabs\">\\n            <li class=\"active\"><a class=\"btn tab-btn\" onclick=\"openTab(event, \\'tab-author\\')\">Author</a></li>\\n            <li><a class=\"btn tab-btn\" onclick=\"openTab(event, \\'tab-venue\\')\">Venue</a></li>\\n            <li><a class=\"btn tab-btn\" onclick=\"openTab(event, \\'tab-inst\\')\">Institution</a></li>\\n            <li><a class=\"btn tab-btn\" onclick=\"openTab(event, \\'tab-topic\\')\">Topic</a></li>\\n          </ul>\\n          <div class=\"flower-tab-content\">\\n            <div class=\"tab-flower active\" id=\"tab-author\"><svg id=\"flower-graph-author\"></svg></div>\\n            <div class=\"tab-flower\" id=\"tab-venue\"><svg id=\"flower-graph-venue\"></svg></div>\\n            <div class=\"tab-flower\" id=\"tab-inst\"><svg id=\"flower-graph-inst\"></svg></div>\\n            <div class=\"tab-flower\" id=\"tab-topic\"><svg id=\"flower-graph-topic\"></svg></div>\\n          </div>\\n        </div>\\n        <div id=\"coreRecommenderOutput\"></div>\\n        <div id=\"iarxivOutput\"></div>\\n      </div>\\n\\n      <input type=\"radio\" name=\"tabs\" id=\"tabfive\">\\n      <label for=\"tabfive\">\\n        About arXivLabs\\n      </label>\\n      <div class=\"tab\">\\n        <div class=\"columns\">\\n          <div class=\"column\">\\n            <h1>arXivLabs: experimental projects with community collaborators</h1>\\n            <p>arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.</p>\\n            <p>Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.</p>\\n            <p>Have an idea for a project that will add value for arXiv\\'s community? <a href=\"https://info.arxiv.org/labs/index.html\"><strong>Learn more about arXivLabs</strong></a>.</p>\\n          </div>\\n          <div class=\"column is-narrow is-full-mobile\">\\n            <p class=\"icon-labs\"><svg xmlns=\"http://www.w3.org/2000/svg\" role=\"presentation\" viewBox=\"0 0 635.572 811\"><path d=\"M175.6 676v27h-27v-27zm-54 27v27h27v-27zm-27 27v27h27v-27zm396-54v27h-27v-27zm0 27v27h27v-27zm27 27v27h27v-27zm-27-414h27v27h-27zm27 0h27v-27h-27zm27-27h27v-27h-27zm-396 45h-27v-27h27zm-27-54h-27v27h27zm-27-27h-27v27h27z\"/><path d=\"M94.6 730v27h-27v-27zm477 0v27h-27v-27zm-27-495h27v27h-27zm-450 18h-27v-27h27zm477 9h27v27h-27zm-54 495h27v27h-27zm-423 0h27v27h-27zm-54-504h27v27h-27z\" fill=\"#666\"/><path d=\"M67.6 730v27h-27v-27zm54 54v27h-27v-27zm0-108v27h27v-27zm-27 27v27h27v-27zm-81 0v27h27v-27zm585 27v27h-27v-27zm-108-54v27h27v-27zm27 27v27h27v-27zm81 0v27h27v-27zm-54-495h27v27h-27zm-54 108h27v-27h-27zm27-27h27v-27h-27zm0-81h27v-27h-27zm-423 18h-27v-27h27zm54 54h-27v27h27zm-27-27h-27v27h27zm0-81h-27v27h27zm423 612v27h-27v-27zm81-522v27h-27v-27zm-585-9v27h-27v-27z\" fill=\"#999\"/><path d=\"M94.6 784v27h-27v-27zm-27-27v27h27v-27zm-27-54v27h27v-27zm27 0v27h27v-27zm0-27v27h27v-27zm27 0v27h27v-27zm0-27v27h27v-27zm27 0v27h27v-27zm-108 81v27h27v-27zm558 54v27h-27v-27zm-27-27v27h27v-27zm27-54v27h27v-27zm-27 0v27h27v-27zm0-27v27h27v-27zm-27 0v27h27v-27zm0-27v27h27v-27zm-27 0v27h27v-27zm108 81v27h27v-27zm0-495h27v27h-27zm-27 27h27v-27h-27zm-54-27h27v-27h-27zm0 27h27v-27h-27zm-27 0h27v-27h-27zm0 27h27v-27h-27zm-27 0h27v-27h-27zm0 27h27v-27h-27zm81-108h27v-27h-27zm-504 45h-27v-27h27zm27-27h-27v27h27zm54-27h-27v27h27zm0 27h-27v27h27zm27 0h-27v27h27zm0 27h-27v27h27zm27 0h-27v27h27zm0 27h-27v27h27zm-81-108h-27v27h27z\" fill=\"#ccc\"/><path d=\"M598.6 665.1H41.5C-76.5 667 176 280.2 176 280.2h53a46.5 46.5 0 0162.8-56.3 29.2 29.2 0 1128.5 35.9h-1a46.5 46.5 0 01-1.5 20.3l142.5-.1s255.3 387 138.3 385.1zM291 181a29.3 29.3 0 10-29.2-29.3A29.3 29.3 0 00291 181zm65.4-66.8a22.4 22.4 0 10-22.5-22.4 22.4 22.4 0 0022.5 22.4z\" fill=\"#fc0\"/><path d=\"M245.5 172V10h153v162s324 495 198 495h-558c-126 0 207-495 207-495zm126 54h56m-13 72h56m-9 72h56m-20 72h56m-22 72h56m-29 72h56m-457-45c20.8 41.7 87.3 81 160.7 81 72.1 0 142.1-38.2 163.4-81\" fill=\"none\" stroke=\"#000\" stroke-miterlimit=\"10\" stroke-width=\"20\"/><path d=\"M273.3 421.7c0 31-9.8 56.3-21.9 56.3s-21.8-25.2-21.8-56.3 9.8-56.3 21.8-56.3 21.9 25.2 21.9 56.3zm114.4-56.3c-12 0-21.8 25.2-21.8 56.3s9.7 56.3 21.8 56.3 21.9-25.2 21.9-56.3-9.8-56.3-21.9-56.3zM150.1 526.6c-18.2 6.7-27.5 22.9-23.2 30.2s14.8-5.5 33-12.2 37.4-4.9 33-12.2-24.5-12.6-42.8-5.8zm296 5.8c-4.2 7.3 14.9 5.5 33.1 12.2s28.7 19.5 33 12.2-5-23.5-23.2-30.2-38.5-1.5-42.8 5.8z\"/></svg></p>\\n          </div>\\n        </div>\\n      </div>\\n\\n    </div>\\n</div>\\n<!-- END LABS AREA -->\\n  <div class=\"endorsers\">\\n    <a href=\"/auth/show-endorsers/1706.03762\" class=\"endorser-who\" rel=\"nofollow\">Which authors of this paper are endorsers?</a> |\\n    <a id=\"mathjax_toggle\" href=\"javascript:setMathjaxCookie()\">Disable MathJax</a> (<a href=\"https://info.arxiv.org/help/mathjax.html\">What is MathJax?</a>)\\n    <span class=\"help\" style=\"font-style: normal; float: right; margin-top: 0; margin-right: 1em;\"></span>\\n  </div>\\n  <script type=\"text/javascript\" language=\"javascript\">mathjaxToggle();</script>\\n</div>\\n      </div>\\n    </main>\\n\\n    <footer style=\"clear: both;\">\\n      <div class=\"columns is-desktop\" role=\"navigation\" aria-label=\"Secondary\" style=\"margin: -0.75em -0.75em 0.75em -0.75em\">\\n        <!-- Macro-Column 1 -->\\n        <div class=\"column\" style=\"padding: 0;\">\\n          <div class=\"columns\">\\n            <div class=\"column\">\\n              <ul style=\"list-style: none; line-height: 2;\">\\n                <li><a href=\"https://info.arxiv.org/about\">About</a></li>\\n                <li><a href=\"https://info.arxiv.org/help\">Help</a></li>\\n              </ul>\\n            </div>\\n            <div class=\"column\">\\n              <ul style=\"list-style: none; line-height: 2;\">\\n                <li>\\n                  <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\" class=\"icon filter-black\" role=\"presentation\"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d=\"M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z\"/></svg>\\n                  <a href=\"https://info.arxiv.org/help/contact.html\"> Contact</a>\\n                </li>\\n                <li>\\n                  <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\" class=\"icon filter-black\" role=\"presentation\"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d=\"M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z\"/></svg>\\n                  <a href=\"https://info.arxiv.org/help/subscribe\"> Subscribe</a>\\n                </li>\\n              </ul>\\n            </div>\\n          </div>\\n        </div>\\n        <!-- End Macro-Column 1 -->\\n        <!-- Macro-Column 2 -->\\n        <div class=\"column\" style=\"padding: 0;\">\\n          <div class=\"columns\">\\n            <div class=\"column\">\\n              <ul style=\"list-style: none; line-height: 2;\">\\n                <li><a href=\"https://info.arxiv.org/help/license/index.html\">Copyright</a></li>\\n                <li><a href=\"https://info.arxiv.org/help/policies/privacy_policy.html\">Privacy Policy</a></li>\\n              </ul>\\n            </div>\\n            <div class=\"column sorry-app-links\">\\n              <ul style=\"list-style: none; line-height: 2;\">\\n                <li><a href=\"https://info.arxiv.org/help/web_accessibility.html\">Web Accessibility Assistance</a></li>\\n                <li>\\n                  <p class=\"help\">\\n                    <a class=\"a11y-main-link\" href=\"https://status.arxiv.org\" target=\"_blank\">arXiv Operational Status <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\" class=\"icon filter-dark_grey\" role=\"presentation\"><path d=\"M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z\"/></svg></a><br>\\n                    Get status notifications via\\n                    <a class=\"is-link\" href=\"https://subscribe.sorryapp.com/24846f03/email/new\" target=\"_blank\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\" class=\"icon filter-black\" role=\"presentation\"><path d=\"M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z\"/></svg>email</a>\\n                    or <a class=\"is-link\" href=\"https://subscribe.sorryapp.com/24846f03/slack/new\" target=\"_blank\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 448 512\" class=\"icon filter-black\" role=\"presentation\"><path d=\"M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z\"/></svg>slack</a>\\n                  </p>\\n                </li>\\n              </ul>\\n            </div>\\n          </div>\\n        </div> <!-- end MetaColumn 2 -->\\n        <!-- End Macro-Column 2 -->\\n      </div>\\n    </footer>\\n  </div>\\n\\n  <script src=\"/static/base/1.0.1/js/member_acknowledgement.js\"></script>\\n\\n</body>\\n\\n</html>'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "arxiv_id = '1706.03762'\n",
    "\n",
    "res = requests.get(f\"https://arxiv.org/abs/{arxiv_id}\")\n",
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "abstract_pattern = re.compile(\n",
    "    r'<blockquote class=\"abstract mathjax\">\\s*<span class=\"descriptor\">Abstract:</span>\\s*(.*?)\\s*</blockquote>',\n",
    "    re.DOTALL\n",
    ")\n",
    "\n",
    "re_match = abstract_pattern.search(res.text)\n",
    "\n",
    "if re_match:\n",
    "    print(re_match.group(1))\n",
    "else:\n",
    "    print(\"Abstract not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import requests\n",
    "import re\n",
    "\n",
    "abstract_pattern = re.compile(\n",
    "    r'<blockquote class=\"abstract mathjax\">\\s*<span class=\"descriptor\">Abstract:</span>\\s*(.*?)\\s*</blockquote>',\n",
    "    re.DOTALL\n",
    ")\n",
    "\n",
    "@tool(\"fetch_arxiv\")\n",
    "def fetch_arxiv(arxiv_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the abstract from an ArXiv paper \n",
    "    \"\"\"\n",
    "    res = requests.get(f\"https://arxiv.org/abs/{arxiv_id}\")\n",
    "\n",
    "    re_match = abstract_pattern.search(res.text)\n",
    "\n",
    "    return re_match.group(1) if re_match else \"Abstract not found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n"
     ]
    }
   ],
   "source": [
    "arxiv_id = '1706.03762'\n",
    "output = fetch_arxiv.invoke(input={'arxiv_id': arxiv_id})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water\n",
      "Water is an inorganic compound with the chemical formula H 2 O. It is a transparent, tasteless, odorless, [c] and nearly colorless chemical substance\n",
      "https://en.wikipedia.org/wiki/Water\n",
      "---\n",
      "Waters Corporation | Laboratory Instruments ...\n",
      "Waters is the leading provider of lab equipment, supplies and software for scientists across the world. Easily research and order everything your lab needs!\n",
      "https://www.waters.com/nextgen/us/en.html?srsltid=AfmBOoqYd8yOakHzeE7BmFKnnOpw96OKebnHEh6ebUtPbmGdEsD2ULRh\n",
      "---\n",
      "Primo Water: Water Delivery for Your Home & Business\n",
      "Stay refreshed anywhere with our reliable beverage and water delivery to your home and office. Experience premium taste and service from Primo Water.\n",
      "https://www.water.com/\n",
      "---\n",
      "Water | H2O | CID 962\n",
      "Water (chemical formula: H2O) is a transparent fluid which forms the world's streams, lakes, oceans and rain, and is the major constituent of the fluids of organisms. As a chemical compound, a water molecule contains one oxygen and two hydrogen atoms that are connected by covalent bonds.\n",
      "https://pubchem.ncbi.nlm.nih.gov/compound/Water\n"
     ]
    }
   ],
   "source": [
    "from serpapi import GoogleSearch\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "serpapi_params = {\n",
    "    \"engine\": \"google\",\n",
    "    \"api_key\": os.getenv(\"SERPAPI_KEY\") or getpass(\"SerpAPI key:\")\n",
    "}\n",
    "\n",
    "search = GoogleSearch({\n",
    "    **serpapi_params, \n",
    "    'q': 'water',\n",
    "    'num': 5\n",
    "})\n",
    "\n",
    "results = search.get_dict().get('organic_results', [])\n",
    "\n",
    "formatted_results = \"\\n---\\n\".join(\n",
    "    ['\\n'.join([x['title'], x['snippet'], x['link']]) for x in results]\n",
    ")\n",
    "\n",
    "print(formatted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water\n",
      "Water is an inorganic compound with the chemical formula H 2 O. It is a transparent, tasteless, odorless, [c] and nearly colorless chemical substance\n",
      "https://en.wikipedia.org/wiki/Water\n",
      "---\n",
      "Waters Corporation | Laboratory Instruments ...\n",
      "Waters is the leading provider of lab equipment, supplies and software for scientists across the world. Easily research and order everything your lab needs!\n",
      "https://www.waters.com/nextgen/us/en.html?srsltid=AfmBOoqYd8yOakHzeE7BmFKnnOpw96OKebnHEh6ebUtPbmGdEsD2ULRh\n",
      "---\n",
      "Primo Water: Water Delivery for Your Home & Business\n",
      "Stay refreshed anywhere with our reliable beverage and water delivery to your home and office. Experience premium taste and service from Primo Water.\n",
      "https://www.water.com/\n",
      "---\n",
      "Water | H2O | CID 962\n",
      "Water (chemical formula: H2O) is a transparent fluid which forms the world's streams, lakes, oceans and rain, and is the major constituent of the fluids of organisms. As a chemical compound, a water molecule contains one oxygen and two hydrogen atoms that are connected by covalent bonds.\n",
      "https://pubchem.ncbi.nlm.nih.gov/compound/Water\n"
     ]
    }
   ],
   "source": [
    "from serpapi import GoogleSearch\n",
    "\n",
    "@tool(\"web_search\")\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Finds general knowledge information using a Google search.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query string.\n",
    "\n",
    "    Rerturns:\n",
    "        str: A formatted string of the top search results, including title, snippet, and link.\n",
    "    \"\"\"\n",
    "\n",
    "    search = GoogleSearch({\n",
    "    **serpapi_params, \n",
    "    'q': 'water',\n",
    "    'num': 5\n",
    "    })\n",
    "\n",
    "    return formatted_results if results else \"No results found.\"\n",
    "\n",
    "\n",
    "output = web_search.invoke(input={\"query\": \"water on mars\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_rag_contexts(matches: list) -> str:\n",
    "    \"\"\"\n",
    "    Formats the retrieved context matches into a readable string format.\n",
    "\n",
    "    Args:\n",
    "        matches (list): A list of matched documents with metadata.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of document titles, chunks, and ArXiv IDs.\n",
    "    \"\"\"\n",
    "\n",
    "    formatted_results = []\n",
    "\n",
    "    for x in matches:\n",
    "        text = (\n",
    "            f\"Title: {x['metadata']['title']}\\n\"\n",
    "            f\"Chunk: {x['metadata']['chunk']}\\n\"\n",
    "            f\"ArXiv ID: {x['metadata']['arxiv_id']}\\n\"\n",
    "        )\n",
    "        formatted_results.append(text)\n",
    "    \n",
    "    return \"\\n---\\n\".join(formatted_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def rag_search_filter(query: str, arxiv_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Finds information from the ArXiv database using a natural language query and a specific ArXiv ID.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query in natural language.\n",
    "        arxiv_id (str): The ArXiv ID of the specific paper to filter by.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of relevant document contexts.\n",
    "    \"\"\"\n",
    "\n",
    "    xq = encoder([query])\n",
    "    xc = index.query(query=xq, top_k=6, include_metadata=True, filter={\"arxiv_id\": arxiv_id})\n",
    "\n",
    "    return format_rag_contexts(xc['matches'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool('rag_search')\n",
    "def rag_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Finds specialist information on AI using a natural language query.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query in natural language.\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string of relevant document contexts.\n",
    "    \"\"\"\n",
    "    xq = encoder([query])\n",
    "    xc = index.query(query=xq, top_k=5, include_metadata=True)\n",
    "\n",
    "    return format_rag_contexts(xc['matches'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def final_answer(\n",
    "    introduction: str,\n",
    "    research_steps: str or list,\n",
    "    main_body: str,\n",
    "    conclusion: str,\n",
    "    sources: str or list\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Returns a natural language response in the form of a research report.\n",
    "\n",
    "    Args:\n",
    "        introduction (str): A short paragraph introducing the user's question and the topic.\n",
    "        research_steps (str or list): Bullet points or text explaining the steps taken for research.\n",
    "        main_body (str): The bulk of the answer, 3-4 paragraphs long, providing high-quality information.\n",
    "        conclusion (str): A short paragraph summarizing the findings.\n",
    "        sources (str or list): A list or text providing the sources referenced during the research.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted research report string.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(research_steps, list):\n",
    "        research_steps = \"\\n\".join([f\"- {r}\" for r in research_steps])\n",
    "    \n",
    "    if isinstance(sources, list):\n",
    "        sources = \"\\n\".join([f\"- {s}\" for s in sources])\n",
    "    \n",
    "    return f\"{introduction}\\n\\nResearch Steps:\\n{research_steps}\\n\\nMain Body:n{main_body}\\n\\nConclusion:\\n{conclusion}\\n\\nSources:\\n{sources}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "system_prompt = (\n",
    "    \"\"\"\n",
    "    You are the oracle, the great AI decision-maker.\n",
    "    Given the user's query, you must decide what to do with it based on the \n",
    "    list of tools provided to you.\n",
    "\n",
    "    If you see that a tool has been used (in the scratchpad) with a particular\n",
    "    query, do NOT use that same tool with the same query again. Also, do NOT use\n",
    "    any tool more than twice (i.e., if the tool appears in the scratchpad twice, do \n",
    "    not use it again).\n",
    "\n",
    "    You should aim to collect information from a diverse range of sources before\n",
    "    providing the answer to the user. Once you have collected plenty of information\n",
    "    to answer the user's question (stored in the scratchpad), use the final_answer tool.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_prompt),\n",
    "    \n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "    \n",
    "    ('user', '{input}'),\n",
    "    \n",
    "    ('assistant', 'scratchpad: {scratchpad}'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolCall, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    rag_search_filter,\n",
    "    rag_search,\n",
    "    fetch_arxiv,\n",
    "    web_search,\n",
    "    final_answer\n",
    "]\n",
    "\n",
    "def create_scratchpad(intermediate_steps: list[ToolCall]) -> str:\n",
    "    research_steps = []\n",
    "\n",
    "    for i, action in enumerate(intermediate_steps):\n",
    "        if action.log != \"TBD\":\n",
    "            research_steps.append(\n",
    "                f\"Tool: {action.tool}, input: {action.tool_input}\\n\"\n",
    "                f\"Output: {action.log}\"\n",
    "            )\n",
    "\n",
    "    return \"\\n---\\n\".join(research_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
